{"ast":null,"code":"/**\n    * @license\n    * Copyright 2021 Google LLC. All Rights Reserved.\n    * Licensed under the Apache License, Version 2.0 (the \"License\");\n    * you may not use this file except in compliance with the License.\n    * You may obtain a copy of the License at\n    *\n    * http://www.apache.org/licenses/LICENSE-2.0\n    *\n    * Unless required by applicable law or agreed to in writing, software\n    * distributed under the License is distributed on an \"AS IS\" BASIS,\n    * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n    * See the License for the specific language governing permissions and\n    * limitations under the License.\n    * =============================================================================\n    */\nimport * as tf from \"@tensorflow/tfjs-core\";\nimport { tidy, sub, div, util, Tensor, browser, image, pad3d, cast, expandDims, squeeze, sigmoid, scalar, mul, reshape, argMax, concat, tensor2d, add } from \"@tensorflow/tfjs-core\";\nimport { loadGraphModel } from \"@tensorflow/tfjs-converter\";\n\nvar extendStatics = function (e, t) {\n  return (extendStatics = Object.setPrototypeOf || {\n    __proto__: []\n  } instanceof Array && function (e, t) {\n    e.__proto__ = t;\n  } || function (e, t) {\n    for (var n in t) t.hasOwnProperty(n) && (e[n] = t[n]);\n  })(e, t);\n};\n\nfunction __extends(e, t) {\n  function n() {\n    this.constructor = e;\n  }\n\n  extendStatics(e, t), e.prototype = null === t ? Object.create(t) : (n.prototype = t.prototype, new n());\n}\n\nvar __assign = function () {\n  return (__assign = Object.assign || function (e) {\n    for (var t, n = 1, r = arguments.length; n < r; n++) for (var o in t = arguments[n]) Object.prototype.hasOwnProperty.call(t, o) && (e[o] = t[o]);\n\n    return e;\n  }).apply(this, arguments);\n};\n\nfunction __awaiter(e, t, n, r) {\n  return new (n || (n = Promise))(function (o, i) {\n    function s(e) {\n      try {\n        a(r.next(e));\n      } catch (e) {\n        i(e);\n      }\n    }\n\n    function u(e) {\n      try {\n        a(r.throw(e));\n      } catch (e) {\n        i(e);\n      }\n    }\n\n    function a(e) {\n      e.done ? o(e.value) : new n(function (t) {\n        t(e.value);\n      }).then(s, u);\n    }\n\n    a((r = r.apply(e, t || [])).next());\n  });\n}\n\nfunction __generator(e, t) {\n  var n,\n      r,\n      o,\n      i,\n      s = {\n    label: 0,\n    sent: function () {\n      if (1 & o[0]) throw o[1];\n      return o[1];\n    },\n    trys: [],\n    ops: []\n  };\n  return i = {\n    next: u(0),\n    throw: u(1),\n    return: u(2)\n  }, \"function\" == typeof Symbol && (i[Symbol.iterator] = function () {\n    return this;\n  }), i;\n\n  function u(i) {\n    return function (u) {\n      return function (i) {\n        if (n) throw new TypeError(\"Generator is already executing.\");\n\n        for (; s;) try {\n          if (n = 1, r && (o = 2 & i[0] ? r.return : i[0] ? r.throw || ((o = r.return) && o.call(r), 0) : r.next) && !(o = o.call(r, i[1])).done) return o;\n\n          switch (r = 0, o && (i = [2 & i[0], o.value]), i[0]) {\n            case 0:\n            case 1:\n              o = i;\n              break;\n\n            case 4:\n              return s.label++, {\n                value: i[1],\n                done: !1\n              };\n\n            case 5:\n              s.label++, r = i[1], i = [0];\n              continue;\n\n            case 7:\n              i = s.ops.pop(), s.trys.pop();\n              continue;\n\n            default:\n              if (!(o = (o = s.trys).length > 0 && o[o.length - 1]) && (6 === i[0] || 2 === i[0])) {\n                s = 0;\n                continue;\n              }\n\n              if (3 === i[0] && (!o || i[1] > o[0] && i[1] < o[3])) {\n                s.label = i[1];\n                break;\n              }\n\n              if (6 === i[0] && s.label < o[1]) {\n                s.label = o[1], o = i;\n                break;\n              }\n\n              if (o && s.label < o[2]) {\n                s.label = o[2], s.ops.push(i);\n                break;\n              }\n\n              o[2] && s.ops.pop(), s.trys.pop();\n              continue;\n          }\n\n          i = t.call(e, s);\n        } catch (e) {\n          i = [6, e], r = 0;\n        } finally {\n          n = o = 0;\n        }\n\n        if (5 & i[0]) throw i[1];\n        return {\n          value: i[0] ? i[1] : void 0,\n          done: !0\n        };\n      }([i, u]);\n    };\n  }\n}\n\nvar BaseModel = function () {\n  function e(e, t) {\n    this.model = e, this.outputStride = t;\n    var n = this.model.inputs[0].shape;\n    util.assert(-1 === n[1] && -1 === n[2], function () {\n      return \"Input shape [\" + n[1] + \", \" + n[2] + \"] must both be equal to or -1\";\n    });\n  }\n\n  return e.prototype.predict = function (e) {\n    var t = this;\n    return tidy(function () {\n      var n = t.preprocessInput(cast(e, \"float32\")),\n          r = expandDims(n, 0),\n          o = t.model.predict(r).map(function (e) {\n        return squeeze(e, [0]);\n      }),\n          i = t.nameOutputResults(o);\n      return {\n        heatmapScores: sigmoid(i.heatmap),\n        offsets: i.offsets,\n        displacementFwd: i.displacementFwd,\n        displacementBwd: i.displacementBwd\n      };\n    });\n  }, e.prototype.dispose = function () {\n    this.model.dispose();\n  }, e;\n}(),\n    MobileNet = function (e) {\n  function t() {\n    return null !== e && e.apply(this, arguments) || this;\n  }\n\n  return __extends(t, e), t.prototype.preprocessInput = function (e) {\n    return tidy(function () {\n      return sub(div(e, 127.5), 1);\n    });\n  }, t.prototype.nameOutputResults = function (e) {\n    return {\n      offsets: e[0],\n      heatmap: e[1],\n      displacementFwd: e[2],\n      displacementBwd: e[3]\n    };\n  }, t;\n}(BaseModel);\n\nfunction half(e) {\n  return Math.floor(e / 2);\n}\n\nvar MaxHeap = function () {\n  function e(e, t) {\n    this.priorityQueue = new Array(e), this.numberOfElements = -1, this.getElementValue = t;\n  }\n\n  return e.prototype.enqueue = function (e) {\n    this.priorityQueue[++this.numberOfElements] = e, this.swim(this.numberOfElements);\n  }, e.prototype.dequeue = function () {\n    var e = this.priorityQueue[0];\n    return this.exchange(0, this.numberOfElements--), this.sink(0), this.priorityQueue[this.numberOfElements + 1] = null, e;\n  }, e.prototype.empty = function () {\n    return -1 === this.numberOfElements;\n  }, e.prototype.size = function () {\n    return this.numberOfElements + 1;\n  }, e.prototype.all = function () {\n    return this.priorityQueue.slice(0, this.numberOfElements + 1);\n  }, e.prototype.max = function () {\n    return this.priorityQueue[0];\n  }, e.prototype.swim = function (e) {\n    for (; e > 0 && this.less(half(e), e);) this.exchange(e, half(e)), e = half(e);\n  }, e.prototype.sink = function (e) {\n    for (; 2 * e <= this.numberOfElements;) {\n      var t = 2 * e;\n      if (t < this.numberOfElements && this.less(t, t + 1) && t++, !this.less(e, t)) break;\n      this.exchange(e, t), e = t;\n    }\n  }, e.prototype.getValueAt = function (e) {\n    return this.getElementValue(this.priorityQueue[e]);\n  }, e.prototype.less = function (e, t) {\n    return this.getValueAt(e) < this.getValueAt(t);\n  }, e.prototype.exchange = function (e, t) {\n    var n = this.priorityQueue[e];\n    this.priorityQueue[e] = this.priorityQueue[t], this.priorityQueue[t] = n;\n  }, e;\n}();\n\nfunction scoreIsMaximumInLocalWindow(e, t, n, r, o, i) {\n  for (var s = i.shape, u = s[0], a = s[1], l = !0, p = Math.max(n - o, 0), c = Math.min(n + o + 1, u), d = p; d < c; ++d) {\n    for (var f = Math.max(r - o, 0), h = Math.min(r + o + 1, a), m = f; m < h; ++m) if (i.get(d, m, e) > t) {\n      l = !1;\n      break;\n    }\n\n    if (!l) break;\n  }\n\n  return l;\n}\n\nfunction buildPartWithScoreQueue(e, t, n) {\n  for (var r = n.shape, o = r[0], i = r[1], s = r[2], u = new MaxHeap(o * i * s, function (e) {\n    return e.score;\n  }), a = 0; a < o; ++a) for (var l = 0; l < i; ++l) for (var p = 0; p < s; ++p) {\n    var c = n.get(a, l, p);\n    c < e || scoreIsMaximumInLocalWindow(p, c, a, l, t, n) && u.enqueue({\n      score: c,\n      part: {\n        heatmapY: a,\n        heatmapX: l,\n        id: p\n      }\n    });\n  }\n\n  return u;\n}\n\nvar partNames = [\"nose\", \"leftEye\", \"rightEye\", \"leftEar\", \"rightEar\", \"leftShoulder\", \"rightShoulder\", \"leftElbow\", \"rightElbow\", \"leftWrist\", \"rightWrist\", \"leftHip\", \"rightHip\", \"leftKnee\", \"rightKnee\", \"leftAnkle\", \"rightAnkle\"],\n    NUM_KEYPOINTS = partNames.length,\n    partIds = partNames.reduce(function (e, t, n) {\n  return e[t] = n, e;\n}, {}),\n    connectedPartNames = [[\"leftHip\", \"leftShoulder\"], [\"leftElbow\", \"leftShoulder\"], [\"leftElbow\", \"leftWrist\"], [\"leftHip\", \"leftKnee\"], [\"leftKnee\", \"leftAnkle\"], [\"rightHip\", \"rightShoulder\"], [\"rightElbow\", \"rightShoulder\"], [\"rightElbow\", \"rightWrist\"], [\"rightHip\", \"rightKnee\"], [\"rightKnee\", \"rightAnkle\"], [\"leftShoulder\", \"rightShoulder\"], [\"leftHip\", \"rightHip\"]],\n    poseChain = [[\"nose\", \"leftEye\"], [\"leftEye\", \"leftEar\"], [\"nose\", \"rightEye\"], [\"rightEye\", \"rightEar\"], [\"nose\", \"leftShoulder\"], [\"leftShoulder\", \"leftElbow\"], [\"leftElbow\", \"leftWrist\"], [\"leftShoulder\", \"leftHip\"], [\"leftHip\", \"leftKnee\"], [\"leftKnee\", \"leftAnkle\"], [\"nose\", \"rightShoulder\"], [\"rightShoulder\", \"rightElbow\"], [\"rightElbow\", \"rightWrist\"], [\"rightShoulder\", \"rightHip\"], [\"rightHip\", \"rightKnee\"], [\"rightKnee\", \"rightAnkle\"]],\n    connectedPartIndices = connectedPartNames.map(function (e) {\n  var t = e[0],\n      n = e[1];\n  return [partIds[t], partIds[n]];\n}),\n    partChannels = [\"left_face\", \"right_face\", \"right_upper_leg_front\", \"right_lower_leg_back\", \"right_upper_leg_back\", \"left_lower_leg_front\", \"left_upper_leg_front\", \"left_upper_leg_back\", \"left_lower_leg_back\", \"right_feet\", \"right_lower_leg_front\", \"left_feet\", \"torso_front\", \"torso_back\", \"right_upper_arm_front\", \"right_upper_arm_back\", \"right_lower_arm_back\", \"left_lower_arm_front\", \"left_upper_arm_front\", \"left_upper_arm_back\", \"left_lower_arm_back\", \"right_hand\", \"right_lower_arm_front\", \"left_hand\"];\n\nfunction getOffsetPoint(e, t, n, r) {\n  return {\n    y: r.get(e, t, n),\n    x: r.get(e, t, n + NUM_KEYPOINTS)\n  };\n}\n\nfunction getImageCoords(e, t, n) {\n  var r = getOffsetPoint(e.heatmapY, e.heatmapX, e.id, n),\n      o = r.y,\n      i = r.x;\n  return {\n    x: e.heatmapX * t + i,\n    y: e.heatmapY * t + o\n  };\n}\n\nfunction clamp(e, t, n) {\n  return e < t ? t : e > n ? n : e;\n}\n\nfunction squaredDistance(e, t, n, r) {\n  var o = n - e,\n      i = r - t;\n  return o * o + i * i;\n}\n\nfunction addVectors(e, t) {\n  return {\n    x: e.x + t.x,\n    y: e.y + t.y\n  };\n}\n\nvar parentChildrenTuples = poseChain.map(function (e) {\n  var t = e[0],\n      n = e[1];\n  return [partIds[t], partIds[n]];\n}),\n    parentToChildEdges = parentChildrenTuples.map(function (e) {\n  return e[1];\n}),\n    childToParentEdges = parentChildrenTuples.map(function (e) {\n  return e[0];\n});\n\nfunction getDisplacement(e, t, n) {\n  var r = n.shape[2] / 2;\n  return {\n    y: n.get(t.y, t.x, e),\n    x: n.get(t.y, t.x, r + e)\n  };\n}\n\nfunction getStridedIndexNearPoint(e, t, n, r) {\n  return {\n    y: clamp(Math.round(e.y / t), 0, n - 1),\n    x: clamp(Math.round(e.x / t), 0, r - 1)\n  };\n}\n\nfunction traverseToTargetKeypoint(e, t, n, r, o, i, s, u) {\n  void 0 === u && (u = 2);\n\n  for (var a = r.shape, l = a[0], p = a[1], c = getDisplacement(e, getStridedIndexNearPoint(t.position, i, l, p), s), d = addVectors(t.position, c), f = 0; f < u; f++) {\n    var h = getStridedIndexNearPoint(d, i, l, p),\n        m = getOffsetPoint(h.y, h.x, n, o);\n    d = addVectors({\n      x: h.x * i,\n      y: h.y * i\n    }, {\n      x: m.x,\n      y: m.y\n    });\n  }\n\n  var g = getStridedIndexNearPoint(d, i, l, p),\n      _ = r.get(g.y, g.x, n);\n\n  return {\n    position: d,\n    part: partNames[n],\n    score: _\n  };\n}\n\nfunction decodePose(e, t, n, r, o, i) {\n  var s = t.shape[2],\n      u = parentToChildEdges.length,\n      a = new Array(s),\n      l = e.part,\n      p = e.score,\n      c = getImageCoords(l, r, n);\n  a[l.id] = {\n    score: p,\n    part: partNames[l.id],\n    position: c\n  };\n\n  for (var d = u - 1; d >= 0; --d) {\n    var f = parentToChildEdges[d],\n        h = childToParentEdges[d];\n    a[f] && !a[h] && (a[h] = traverseToTargetKeypoint(d, a[f], h, t, n, r, i));\n  }\n\n  for (d = 0; d < u; ++d) {\n    f = childToParentEdges[d], h = parentToChildEdges[d];\n    a[f] && !a[h] && (a[h] = traverseToTargetKeypoint(d, a[f], h, t, n, r, o));\n  }\n\n  return a;\n}\n\nfunction withinNmsRadiusOfCorrespondingPoint(e, t, n, r) {\n  var o = n.x,\n      i = n.y;\n  return e.some(function (e) {\n    var n = e.keypoints[r].position;\n    return squaredDistance(i, o, n.y, n.x) <= t;\n  });\n}\n\nfunction getInstanceScore(e, t, n) {\n  return n.reduce(function (n, r, o) {\n    var i = r.position,\n        s = r.score;\n    return withinNmsRadiusOfCorrespondingPoint(e, t, i, o) || (n += s), n;\n  }, 0) / n.length;\n}\n\nvar kLocalMaximumRadius = 1;\n\nfunction decodeMultiplePoses(e, t, n, r, o, i, s, u) {\n  void 0 === s && (s = .5), void 0 === u && (u = 20);\n\n  for (var a = [], l = buildPartWithScoreQueue(s, kLocalMaximumRadius, e), p = u * u; a.length < i && !l.empty();) {\n    var c = l.dequeue();\n\n    if (!withinNmsRadiusOfCorrespondingPoint(a, p, getImageCoords(c.part, o, t), c.part.id)) {\n      var d = decodePose(c, e, t, o, n, r),\n          f = getInstanceScore(a, p, d);\n      a.push({\n        keypoints: d,\n        score: f\n      });\n    }\n  }\n\n  return a;\n}\n\nfunction mod(e, t) {\n  return tidy(function () {\n    var n = div(e, scalar(t, \"int32\"));\n    return sub(e, mul(n, scalar(t, \"int32\")));\n  });\n}\n\nfunction argmax2d(e) {\n  var t = e.shape,\n      n = t[0],\n      r = t[1],\n      o = t[2];\n  return tidy(function () {\n    var t = reshape(e, [n * r, o]),\n        i = argMax(t, 0),\n        s = expandDims(div(i, scalar(r, \"int32\")), 1),\n        u = expandDims(mod(i, r), 1);\n    return concat([s, u], 1);\n  });\n}\n\nfunction getPointsConfidence(e, t) {\n  for (var n = t.shape[0], r = new Float32Array(n), o = 0; o < n; o++) {\n    var i = t.get(o, 0),\n        s = t.get(o, 1);\n    r[o] = e.get(i, s, o);\n  }\n\n  return r;\n}\n\nfunction getOffsetPoint$1(e, t, n, r) {\n  return {\n    y: r.get(e, t, n),\n    x: r.get(e, t, n + NUM_KEYPOINTS)\n  };\n}\n\nfunction getOffsetVectors(e, t) {\n  for (var n = [], r = 0; r < NUM_KEYPOINTS; r++) {\n    var o = getOffsetPoint$1(e.get(r, 0).valueOf(), e.get(r, 1).valueOf(), r, t),\n        i = o.x,\n        s = o.y;\n    n.push(s), n.push(i);\n  }\n\n  return tensor2d(n, [NUM_KEYPOINTS, 2]);\n}\n\nfunction getOffsetPoints(e, t, n) {\n  return tidy(function () {\n    var r = getOffsetVectors(e, n);\n    return add(cast(mul(e.toTensor(), scalar(t, \"int32\")), \"float32\"), r);\n  });\n}\n\nfunction decodeSinglePose(e, t, n) {\n  return __awaiter(this, void 0, void 0, function () {\n    var r, o, i, s, u, a, l, p, c, d;\n    return __generator(this, function (f) {\n      switch (f.label) {\n        case 0:\n          return r = 0, o = argmax2d(e), [4, Promise.all([e.buffer(), t.buffer(), o.buffer()])];\n\n        case 1:\n          return i = f.sent(), s = i[0], u = i[1], a = i[2], [4, (l = getOffsetPoints(a, n, u)).buffer()];\n\n        case 2:\n          return p = f.sent(), c = Array.from(getPointsConfidence(s, a)), d = c.map(function (e, t) {\n            return r += e, {\n              position: {\n                y: p.get(t, 0),\n                x: p.get(t, 1)\n              },\n              part: partNames[t],\n              score: e\n            };\n          }), o.dispose(), l.dispose(), [2, {\n            keypoints: d,\n            score: r / d.length\n          }];\n      }\n    });\n  });\n}\n\nvar MOBILENET_BASE_URL = \"https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/\",\n    RESNET50_BASE_URL = \"https://storage.googleapis.com/tfjs-models/savedmodel/posenet/resnet50/\";\n\nfunction resNet50Checkpoint(e, t) {\n  var n = \"model-stride\" + e + \".json\";\n  return 4 === t ? RESNET50_BASE_URL + \"float/\" + n : RESNET50_BASE_URL + \"quant\" + t + \"/\" + n;\n}\n\nfunction mobileNetCheckpoint(e, t, n) {\n  var r = {\n    1: \"100\",\n    .75: \"075\",\n    .5: \"050\"\n  },\n      o = \"model-stride\" + e + \".json\";\n  return 4 === n ? MOBILENET_BASE_URL + \"float/\" + r[t] + \"/\" + o : MOBILENET_BASE_URL + \"quant\" + n + \"/\" + r[t] + \"/\" + o;\n}\n\nvar imageNetMean = [-123.15, -115.9, -103.06],\n    ResNet = function (e) {\n  function t() {\n    return null !== e && e.apply(this, arguments) || this;\n  }\n\n  return __extends(t, e), t.prototype.preprocessInput = function (e) {\n    return add(e, imageNetMean);\n  }, t.prototype.nameOutputResults = function (e) {\n    var t = e[0],\n        n = e[1];\n    return {\n      offsets: e[2],\n      heatmap: e[3],\n      displacementFwd: t,\n      displacementBwd: n\n    };\n  }, t;\n}(BaseModel);\n\nfunction eitherPointDoesntMeetConfidence(e, t, n) {\n  return e < n || t < n;\n}\n\nfunction getAdjacentKeyPoints(e, t) {\n  return connectedPartIndices.reduce(function (n, r) {\n    var o = r[0],\n        i = r[1];\n    return eitherPointDoesntMeetConfidence(e[o].score, e[i].score, t) ? n : (n.push([e[o], e[i]]), n);\n  }, []);\n}\n\nvar NEGATIVE_INFINITY = Number.NEGATIVE_INFINITY,\n    POSITIVE_INFINITY = Number.POSITIVE_INFINITY;\n\nfunction getBoundingBox(e) {\n  return e.reduce(function (e, t) {\n    var n = e.maxX,\n        r = e.maxY,\n        o = e.minX,\n        i = e.minY,\n        s = t.position,\n        u = s.x,\n        a = s.y;\n    return {\n      maxX: Math.max(n, u),\n      maxY: Math.max(r, a),\n      minX: Math.min(o, u),\n      minY: Math.min(i, a)\n    };\n  }, {\n    maxX: NEGATIVE_INFINITY,\n    maxY: NEGATIVE_INFINITY,\n    minX: POSITIVE_INFINITY,\n    minY: POSITIVE_INFINITY\n  });\n}\n\nfunction getBoundingBoxPoints(e) {\n  var t = getBoundingBox(e),\n      n = t.minX,\n      r = t.minY,\n      o = t.maxX,\n      i = t.maxY;\n  return [{\n    x: n,\n    y: r\n  }, {\n    x: o,\n    y: r\n  }, {\n    x: o,\n    y: i\n  }, {\n    x: n,\n    y: i\n  }];\n}\n\nfunction toTensorBuffers3D(e) {\n  return __awaiter(this, void 0, void 0, function () {\n    return __generator(this, function (t) {\n      return [2, Promise.all(e.map(function (e) {\n        return e.buffer();\n      }))];\n    });\n  });\n}\n\nfunction scalePose(e, t, n, r, o) {\n  return void 0 === r && (r = 0), void 0 === o && (o = 0), {\n    score: e.score,\n    keypoints: e.keypoints.map(function (e) {\n      var i = e.score,\n          s = e.part,\n          u = e.position;\n      return {\n        score: i,\n        part: s,\n        position: {\n          x: u.x * n + o,\n          y: u.y * t + r\n        }\n      };\n    })\n  };\n}\n\nfunction scalePoses(e, t, n, r, o) {\n  return void 0 === r && (r = 0), void 0 === o && (o = 0), 1 === n && 1 === t && 0 === r && 0 === o ? e : e.map(function (e) {\n    return scalePose(e, t, n, r, o);\n  });\n}\n\nfunction flipPoseHorizontal(e, t) {\n  return {\n    score: e.score,\n    keypoints: e.keypoints.map(function (e) {\n      var n = e.score,\n          r = e.part,\n          o = e.position;\n      return {\n        score: n,\n        part: r,\n        position: {\n          x: t - 1 - o.x,\n          y: o.y\n        }\n      };\n    })\n  };\n}\n\nfunction flipPosesHorizontal(e, t) {\n  return t <= 0 ? e : e.map(function (e) {\n    return flipPoseHorizontal(e, t);\n  });\n}\n\nfunction toValidInputResolution(e, t) {\n  return isValidInputResolution(e, t) ? e : Math.floor(e / t) * t + 1;\n}\n\nfunction validateInputResolution(e) {\n  util.assert(\"number\" == typeof e || \"object\" == typeof e, function () {\n    return \"Invalid inputResolution \" + e + \". Should be a number or an object with width and height\";\n  }), \"object\" == typeof e && (util.assert(\"number\" == typeof e.width, function () {\n    return \"inputResolution.width has a value of \" + e.width + \" which is invalid; it must be a number\";\n  }), util.assert(\"number\" == typeof e.height, function () {\n    return \"inputResolution.height has a value of \" + e.height + \" which is invalid; it must be a number\";\n  }));\n}\n\nfunction getValidInputResolutionDimensions(e, t) {\n  return validateInputResolution(e), \"object\" == typeof e ? [toValidInputResolution(e.height, t), toValidInputResolution(e.width, t)] : [toValidInputResolution(e, t), toValidInputResolution(e, t)];\n}\n\nvar VALID_OUTPUT_STRIDES = [8, 16, 32];\n\nfunction assertValidOutputStride(e) {\n  util.assert(\"number\" == typeof e, function () {\n    return \"outputStride is not a number\";\n  }), util.assert(VALID_OUTPUT_STRIDES.indexOf(e) >= 0, function () {\n    return \"outputStride of \" + e + \" is invalid. It must be either 8, 16, or 32\";\n  });\n}\n\nfunction isValidInputResolution(e, t) {\n  return (e - 1) % t == 0;\n}\n\nfunction assertValidResolution(e, t) {\n  util.assert(\"number\" == typeof e[0] && \"number\" == typeof e[1], function () {\n    return \"both resolution values must be a number but had values \" + e;\n  }), util.assert(isValidInputResolution(e[0], t), function () {\n    return \"height of \" + e[0] + \" is invalid for output stride \" + t + \".\";\n  }), util.assert(isValidInputResolution(e[1], t), function () {\n    return \"width of \" + e[1] + \" is invalid for output stride \" + t + \".\";\n  });\n}\n\nfunction getInputTensorDimensions(e) {\n  return e instanceof Tensor ? [e.shape[0], e.shape[1]] : [e.height, e.width];\n}\n\nfunction toInputTensor(e) {\n  return e instanceof Tensor ? e : browser.fromPixels(e);\n}\n\nfunction padAndResizeTo(e, t) {\n  var n = t[0],\n      r = t[1],\n      o = getInputTensorDimensions(e),\n      i = o[0],\n      s = o[1],\n      u = r / n,\n      a = [0, 0, 0, 0],\n      l = a[0],\n      p = a[1],\n      c = a[2],\n      d = a[3];\n  return s / i < u ? (l = 0, p = 0, c = Math.round(.5 * (u * i - s)), d = Math.round(.5 * (u * i - s))) : (l = Math.round(.5 * (1 / u * s - i)), p = Math.round(.5 * (1 / u * s - i)), c = 0, d = 0), {\n    resized: tidy(function () {\n      var t = toInputTensor(e);\n      return t = pad3d(t, [[l, p], [c, d], [0, 0]]), image.resizeBilinear(t, [n, r]);\n    }),\n    padding: {\n      top: l,\n      left: c,\n      right: d,\n      bottom: p\n    }\n  };\n}\n\nfunction scaleAndFlipPoses(e, t, n, r, o) {\n  var i = t[0],\n      s = t[1],\n      u = n[0],\n      a = n[1],\n      l = scalePoses(e, (i + r.top + r.bottom) / u, (s + r.left + r.right) / a, -r.top, -r.left);\n  return o ? flipPosesHorizontal(l, s) : l;\n}\n\nvar MOBILENET_V1_CONFIG = {\n  architecture: \"MobileNetV1\",\n  outputStride: 16,\n  multiplier: .75,\n  inputResolution: 257\n},\n    VALID_ARCHITECTURE = [\"MobileNetV1\", \"ResNet50\"],\n    VALID_STRIDE = {\n  MobileNetV1: [8, 16, 32],\n  ResNet50: [32, 16]\n},\n    VALID_MULTIPLIER = {\n  MobileNetV1: [.5, .75, 1],\n  ResNet50: [1]\n},\n    VALID_QUANT_BYTES = [1, 2, 4];\n\nfunction validateModelConfig(e) {\n  if (null == (e = e || MOBILENET_V1_CONFIG).architecture && (e.architecture = \"MobileNetV1\"), VALID_ARCHITECTURE.indexOf(e.architecture) < 0) throw new Error(\"Invalid architecture \" + e.architecture + \". Should be one of \" + VALID_ARCHITECTURE);\n  if (null == e.inputResolution && (e.inputResolution = 257), validateInputResolution(e.inputResolution), null == e.outputStride && (e.outputStride = 16), VALID_STRIDE[e.architecture].indexOf(e.outputStride) < 0) throw new Error(\"Invalid outputStride \" + e.outputStride + \". Should be one of \" + VALID_STRIDE[e.architecture] + \" for architecture \" + e.architecture + \".\");\n  if (null == e.multiplier && (e.multiplier = 1), VALID_MULTIPLIER[e.architecture].indexOf(e.multiplier) < 0) throw new Error(\"Invalid multiplier \" + e.multiplier + \". Should be one of \" + VALID_MULTIPLIER[e.architecture] + \" for architecture \" + e.architecture + \".\");\n  if (null == e.quantBytes && (e.quantBytes = 4), VALID_QUANT_BYTES.indexOf(e.quantBytes) < 0) throw new Error(\"Invalid quantBytes \" + e.quantBytes + \". Should be one of \" + VALID_QUANT_BYTES + \" for architecture \" + e.architecture + \".\");\n  if (\"MobileNetV1\" === e.architecture && 32 === e.outputStride && 1 !== e.multiplier) throw new Error(\"When using an output stride of 32, you must select 1 as the multiplier.\");\n  return e;\n}\n\nvar SINGLE_PERSON_INFERENCE_CONFIG = {\n  flipHorizontal: !1\n},\n    MULTI_PERSON_INFERENCE_CONFIG = {\n  flipHorizontal: !1,\n  maxDetections: 5,\n  scoreThreshold: .5,\n  nmsRadius: 20\n};\n\nfunction validateMultiPersonInputConfig(e) {\n  var t = e.maxDetections,\n      n = e.scoreThreshold,\n      r = e.nmsRadius;\n  if (t <= 0) throw new Error(\"Invalid maxDetections \" + t + \". Should be > 0\");\n  if (n < 0 || n > 1) throw new Error(\"Invalid scoreThreshold \" + n + \". Should be in range [0.0, 1.0]\");\n  if (r <= 0) throw new Error(\"Invalid nmsRadius \" + r + \".\");\n}\n\nvar PoseNet = function () {\n  function e(e, t) {\n    assertValidOutputStride(e.outputStride), assertValidResolution(t, e.outputStride), this.baseModel = e, this.inputResolution = t;\n  }\n\n  return e.prototype.estimateMultiplePoses = function (e, t) {\n    return void 0 === t && (t = MULTI_PERSON_INFERENCE_CONFIG), __awaiter(this, void 0, void 0, function () {\n      var n, r, o, i, s, u, a, l, p, c, d, f, h, m, g, _, I, v, y, E, b;\n\n      return __generator(this, function (N) {\n        switch (N.label) {\n          case 0:\n            return n = __assign({}, MULTI_PERSON_INFERENCE_CONFIG, t), validateMultiPersonInputConfig(t), r = this.baseModel.outputStride, o = this.inputResolution, i = getInputTensorDimensions(e), s = i[0], u = i[1], a = padAndResizeTo(e, o), l = a.resized, p = a.padding, c = this.baseModel.predict(l), d = c.heatmapScores, f = c.offsets, h = c.displacementFwd, m = c.displacementBwd, [4, toTensorBuffers3D([d, f, h, m])];\n\n          case 1:\n            return g = N.sent(), _ = g[0], I = g[1], v = g[2], y = g[3], [4, decodeMultiplePoses(_, I, v, y, r, n.maxDetections, n.scoreThreshold, n.nmsRadius)];\n\n          case 2:\n            return E = N.sent(), b = scaleAndFlipPoses(E, [s, u], o, p, n.flipHorizontal), d.dispose(), f.dispose(), h.dispose(), m.dispose(), l.dispose(), [2, b];\n        }\n      });\n    });\n  }, e.prototype.estimateSinglePose = function (e, t) {\n    return void 0 === t && (t = SINGLE_PERSON_INFERENCE_CONFIG), __awaiter(this, void 0, void 0, function () {\n      var n, r, o, i, s, u, a, l, p, c, d, f, h, m, g, _;\n\n      return __generator(this, function (I) {\n        switch (I.label) {\n          case 0:\n            return n = __assign({}, SINGLE_PERSON_INFERENCE_CONFIG, t), r = this.baseModel.outputStride, o = this.inputResolution, i = getInputTensorDimensions(e), s = i[0], u = i[1], a = padAndResizeTo(e, o), l = a.resized, p = a.padding, c = this.baseModel.predict(l), d = c.heatmapScores, f = c.offsets, h = c.displacementFwd, m = c.displacementBwd, [4, decodeSinglePose(d, f, r)];\n\n          case 1:\n            return g = I.sent(), _ = scaleAndFlipPoses([g], [s, u], o, p, n.flipHorizontal), d.dispose(), f.dispose(), h.dispose(), m.dispose(), l.dispose(), [2, _[0]];\n        }\n      });\n    });\n  }, e.prototype.estimatePoses = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      return __generator(this, function (n) {\n        switch (n.label) {\n          case 0:\n            return \"single-person\" !== t.decodingMethod ? [3, 2] : [4, this.estimateSinglePose(e, t)];\n\n          case 1:\n            return [2, [n.sent()]];\n\n          case 2:\n            return [2, this.estimateMultiplePoses(e, t)];\n        }\n      });\n    });\n  }, e.prototype.dispose = function () {\n    this.baseModel.dispose();\n  }, e;\n}();\n\nfunction loadMobileNet(e) {\n  return __awaiter(this, void 0, void 0, function () {\n    var t, n, r, o, i, s, u;\n    return __generator(this, function (a) {\n      switch (a.label) {\n        case 0:\n          if (t = e.outputStride, n = e.quantBytes, r = e.multiplier, null == tf) throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please also include @tensorflow/tfjs on the page before using this\\n        model.\");\n          return o = mobileNetCheckpoint(t, r, n), [4, loadGraphModel(e.modelUrl || o)];\n\n        case 1:\n          return i = a.sent(), s = new MobileNet(i, t), u = getValidInputResolutionDimensions(e.inputResolution, s.outputStride), [2, new PoseNet(s, u)];\n      }\n    });\n  });\n}\n\nfunction loadResNet(e) {\n  return __awaiter(this, void 0, void 0, function () {\n    var t, n, r, o, i, s;\n    return __generator(this, function (u) {\n      switch (u.label) {\n        case 0:\n          if (t = e.outputStride, n = e.quantBytes, null == tf) throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please also include @tensorflow/tfjs on the page before using this\\n        model.\");\n          return r = resNet50Checkpoint(t, n), [4, loadGraphModel(e.modelUrl || r)];\n\n        case 1:\n          return o = u.sent(), i = new ResNet(o, t), s = getValidInputResolutionDimensions(e.inputResolution, i.outputStride), [2, new PoseNet(i, s)];\n      }\n    });\n  });\n}\n\nfunction load(e) {\n  return void 0 === e && (e = MOBILENET_V1_CONFIG), __awaiter(this, void 0, void 0, function () {\n    return __generator(this, function (t) {\n      return \"ResNet50\" === (e = validateModelConfig(e)).architecture ? [2, loadResNet(e)] : \"MobileNetV1\" === e.architecture ? [2, loadMobileNet(e)] : [2, null];\n    });\n  });\n}\n\nvar version = \"2.2.2\";\nexport { decodeMultiplePoses, decodeSinglePose, MobileNet, partChannels, partIds, partNames, poseChain, load, PoseNet, getAdjacentKeyPoints, getBoundingBox, getBoundingBoxPoints, scaleAndFlipPoses, scalePose, version };","map":{"version":3,"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8BA;;AAAA;AACE,aACuBA,CADvB,EAEoBC,CAFpB,EAEoBA;AADGC,oBACHA,qBADGA;AAErB,QAAMC,IACFD,KAAKF,KAALE,CAAWE,MAAXF,CAAkB,CAAlBA,EAAqBG,KADzB;AAEAC,SAAQC,MAARD,CAAQC,CACgB,CADhBA,KACHJ,EAAW,CAAXA,CADGI,IACQ,CAAkC,CAAlC,KAAeJ,EAAW,CAAXA,CAD/BG,EAEI;AAAM,+BAAgBH,EAAW,CAAXA,CAAhB,GAA2B,IAA3B,GAAkCA,EAAW,CAAXA,CAAlC,GAA6C,+BAA7C;AAA6C,KAFvDG;AA2DJ;;AAAA,SAtCEE,gCAAQC,CAAR,EAAQA;AAAR;AAME,WAAOC,KAAQ;AACb,UAAMC,IAAUC,EAAKC,eAALD,CAAqBE,KAAQL,CAARK,EAAe,SAAfA,CAArBF,CAAhB;AAAA,UACMG,IAAUC,WAAcL,CAAdK,EAAuB,CAAvBA,CADhB;AAAA,UAGMC,IADUL,EAAKZ,KAALY,CAAWM,OAAXN,CAAmBG,CAAnBH,EACyBO,GADzBP,CAC6B;AAAK,uBAAWQ,CAAXC,EAAWD,CAAI,CAAJA,CAAXC;AAAe,OADjDT,CAFhB;AAAA,UAKMU,IAAeV,EAAKW,iBAALX,CAAuBK,CAAvBL,CALrB;AAOA;AACEY,uBAAeC,QAAWH,EAAaI,OAAxBD,CADjB;AAEEE,iBAASL,EAAaK,OAFxB;AAGEC,yBAAiBN,EAAaM,eAHhC;AAIEC,yBAAiBP,EAAaO;AAJhC;AAIgCA,KAZ3BnB,CAAP;AAYkCmB,GAlBpCrB,EAmCAA;AACEN,SAAKF,KAALE,CAAW4B,OAAX5B;AAAW4B,GApCbtB,EAoCasB,CAEf;AAFeA,CA/Df;AAAA,IA+DeA;ACzEf;AAAA;AAUA;;AAAA,SAV+BC,iBAC7BC,wCAAgBvB,CAAhB,EAAgBA;AAEd,WAAOC,KAAQ;AAAM,iBAAOuB,IAAOxB,CAAPwB,EAAc,KAAdA,CAAPC,EAA6B,CAA7BA;AAA6B,KAA3CxB,CAAP;AAAkD,GAHvBqB,EAM7BC,0CAAkBG,CAAlB,EAAkBA;AAEhB;AAAQR,mBAAR;AAAiBD,mBAAjB;AAA0BE,2BAA1B;AAA2CC;AAA3C;AAA2CA,GARhBE,EAQgBF,CAE/C;AAF+CA,CDiEhCC,CCzEgBtB,SDyEhBsB,CA/Df;;AEVA,SAASM,IAAT,CAAcC,CAAd,EAAcA;AACZ,SAAOC,KAAKC,KAALD,CAAWD,IAAI,CAAfC,CAAP;AAGF;;AAAA;AAKE,aAAYE,CAAZ,EAA6BC,CAA7B,EAA6BA;AAC3BvC,SAAKwC,aAALxC,GAAqB,IAAIyC,KAAJ,CAAUH,CAAV,CAArBtC,EACAA,KAAK0C,gBAAL1C,GAAK0C,CAAoB,CADzB1C,EAEAA,KAAKuC,eAALvC,GAAuBuC,CAFvBvC;AAoEJ;;AAAA,SA/DS2C,sBAAP,UAAeC,CAAf,EAAeA;AACb5C,SAAKwC,aAALxC,CAAKwC,EAAgBxC,KAAK0C,gBAA1B1C,IAA8C4C,CAA9C5C,EACAA,KAAK6C,IAAL7C,CAAUA,KAAK0C,gBAAf1C,CADAA;AACe0C,GAFVC,EAKAA,sBAAP;AACE,QAAMG,IAAM9C,KAAKwC,aAALxC,CAAmB,CAAnBA,CAAZ;AAIA,WAHAA,KAAK+C,QAAL/C,CAAc,CAAdA,EAAiBA,KAAK0C,gBAAL1C,EAAjBA,GACAA,KAAKgD,IAALhD,CAAU,CAAVA,CADAA,EAEAA,KAAKwC,aAALxC,CAAmBA,KAAK0C,gBAAL1C,GAAwB,CAA3CA,IAAgD,IAFhDA,EAGO8C,CAAP;AAAOA,GAVFH,EAaAA,oBAAP;AACE,YAAkC,CAAlC,KAAO3C,KAAK0C,gBAAZ;AAAYA,GAdPC,EAiBAA,mBAAP;AACE,WAAO3C,KAAK0C,gBAAL1C,GAAwB,CAA/B;AAA+B,GAlB1B2C,EAqBAA,kBAAP;AACE,WAAO3C,KAAKwC,aAALxC,CAAmBiD,KAAnBjD,CAAyB,CAAzBA,EAA4BA,KAAK0C,gBAAL1C,GAAwB,CAApDA,CAAP;AAA2D,GAtBtD2C,EAyBAA,kBAAP;AACE,WAAO3C,KAAKwC,aAALxC,CAAmB,CAAnBA,CAAP;AAA0B,GA1BrB2C,EA6BCA,mBAAR,UAAaR,CAAb,EAAaA;AACX,WAAOA,IAAI,CAAJA,IAASnC,KAAKkD,IAALlD,CAAUkC,KAAKC,CAALD,CAAVlC,EAAmBmC,CAAnBnC,CAAhB,GACEA,KAAK+C,QAAL/C,CAAcmC,CAAdnC,EAAiBkC,KAAKC,CAALD,CAAjBlC,GACAmC,IAAID,KAAKC,CAALD,CADJlC;AACSmC,GAhCNQ,EAoCCA,mBAAR,UAAaR,CAAb,EAAaA;AACX,WAAO,IAAIA,CAAJ,IAASnC,KAAK0C,gBAArB,GAAuC;AACrC,UAAIS,IAAI,IAAIhB,CAAZ;AAIA,UAHIgB,IAAInD,KAAK0C,gBAATS,IAA6BnD,KAAKkD,IAALlD,CAAUmD,CAAVnD,EAAamD,IAAI,CAAjBnD,CAA7BmD,IACFA,GADEA,EACFA,CAEGnD,KAAKkD,IAALlD,CAAUmC,CAAVnC,EAAamD,CAAbnD,CAAL,EACE;AAEFA,WAAK+C,QAAL/C,CAAcmC,CAAdnC,EAAiBmD,CAAjBnD,GACAmC,IAAIgB,CADJnD;AACImD;AAAAA,GA9CDR,EAkDCA,yBAAR,UAAmBS,CAAnB,EAAmBA;AACjB,WAAOpD,KAAKuC,eAALvC,CAAqBA,KAAKwC,aAALxC,CAAmBoD,CAAnBpD,CAArBA,CAAP;AAA+CoD,GAnD1CT,EAsDCA,mBAAR,UAAaS,CAAb,EAAwBD,CAAxB,EAAwBA;AACtB,WAAOnD,KAAKqD,UAALrD,CAAgBoD,CAAhBpD,IAAqBA,KAAKqD,UAALrD,CAAgBmD,CAAhBnD,CAA5B;AAA4CmD,GAvDvCR,EA0DCA,uBAAR,UAAiBS,CAAjB,EAA4BD,CAA5B,EAA4BA;AAC1B,QAAMG,IAAItD,KAAKwC,aAALxC,CAAmBoD,CAAnBpD,CAAV;AACAA,SAAKwC,aAALxC,CAAmBoD,CAAnBpD,IAAwBA,KAAKwC,aAALxC,CAAmBmD,CAAnBnD,CAAxBA,EACAA,KAAKwC,aAALxC,CAAmBmD,CAAnBnD,IAAwBsD,CADxBtD;AACwBsD,GA7DnBX,EA6DmBW,CAE5B;AAF4BA,CAxE5B;;ACLA,SAESC,2BAFT,CAGIC,CAHJ,EAGwBC,CAHxB,EAGuCC,CAHvC,EAGyDC,CAHzD,EAIIC,CAJJ,EAIgCC,CAJhC,EAIgCA;AAM9B,OALM,iBAACC,QAAD,EAASC,QAAT,EAEFC,KAAe,CAFb,EAGAC,IAAS7B,KAAKU,GAALV,CAASsB,IAAWE,CAApBxB,EAAwC,CAAxCA,CAHT,EAIA8B,IAAO9B,KAAK+B,GAAL/B,CAASsB,IAAWE,CAAXF,GAAgC,CAAzCtB,EAA4C0B,CAA5C1B,CAJP,EAKGgC,IAAWH,CAApB,EAA4BG,IAAWF,CAAvC,EAAuCA,EAAQE,CAA/C,EAAyD;AAGvD,SAFA,IAAMC,IAASjC,KAAKU,GAALV,CAASuB,IAAWC,CAApBxB,EAAwC,CAAxCA,CAAf,EACMkC,IAAOlC,KAAK+B,GAAL/B,CAASuB,IAAWC,CAAXD,GAAgC,CAAzCvB,EAA4C2B,CAA5C3B,CADb,EAESmC,IAAWF,CAApB,EAA4BE,IAAWD,CAAvC,EAAuCA,EAAQC,CAA/C,EACE,IAAIV,EAAOW,GAAPX,CAAWO,CAAXP,EAAqBU,CAArBV,EAA+BL,CAA/BK,IAA6CJ,CAAjD,EAAwD;AACtDO,WAAe,CAAfA;AACA;AAGJ;;AAAA,SAAKA,CAAL,EACE;AAIJ;;AAAA,SAAOA,CAAP;AAQF;;AAAA,SAAgBS,uBAAhB,CACIC,CADJ,EAC4Bd,CAD5B,EAEIC,CAFJ,EAEIA;AAMF,OALM,iBAACC,QAAD,EAASC,QAAT,EAAgBY,QAAhB,EAEAC,IAAQ,IAAIjC,OAAJ,CACVmB,IAASC,CAATD,GAAiBa,CADP,EACqB,UAACE,CAAD,EAACA;AAAY;AAAA,GADlC,CAFR,EAKGnB,IAAW,CAApB,EAAuBA,IAAWI,CAAlC,EAAkCA,EAAUJ,CAA5C,EACE,KAAK,IAAIC,IAAW,CAApB,EAAuBA,IAAWI,CAAlC,EAAkCA,EAASJ,CAA3C,EACE,KAAK,IAAIH,IAAa,CAAtB,EAAyBA,IAAamB,CAAtC,EAAsCA,EAAgBnB,CAAtD,EAAkE;AAChE,QAAMC,IAAQI,EAAOW,GAAPX,CAAWH,CAAXG,EAAqBF,CAArBE,EAA+BL,CAA/BK,CAAd;AAIIJ,QAAQiB,CAARjB,IAKAF,4BACIC,CADJD,EACgBE,CADhBF,EACuBG,CADvBH,EACiCI,CADjCJ,EAC2CK,CAD3CL,EAEIM,CAFJN,KAGFqB,EAAME,OAANF,CAAME;AAASrB,cAATqB;AAAgBC;AAAOrB,mBAAPqB;AAAiBpB,mBAAjBoB;AAA2BC,YAAIxB;AAA/BuB;AAAhBD,KAANF,CAREnB;AAcV;;AAAA,SAAOmB,CAAP;AC3DF;;AAAA,IAAaK,aACX,MADWA,EACH,SADGA,EACQ,UADRA,EACoB,SADpBA,EAC+B,UAD/BA,EAC2C,cAD3CA,EAEX,eAFWA,EAEM,WAFNA,EAEmB,YAFnBA,EAEiC,WAFjCA,EAE8C,YAF9CA,EAGX,SAHWA,EAGA,UAHAA,EAGY,UAHZA,EAGwB,WAHxBA,EAGqC,WAHrCA,EAGkD,YAHlDA,CAAb;AAAA,IAMaC,gBAAgBD,UAAUE,MANvC;AAAA,IAYaC,UACTH,UAAUI,MAAVJ,CAAiB,UAACK,CAAD,EAAqBC,CAArB,EAAgCnC,CAAhC,EAAgCA;AAE/C,SADAkC,EAAOC,CAAPD,IAAoBlC,CAApBkC,EACOA,CAAP;AAAOA,CAFTL,EAESK,EAFTL,CAbJ;AAAA,IAkBMO,uBACH,SADGA,EACQ,cADRA,GACQ,CAAkB,WAAlB,EAA+B,cAA/B,CADRA,EACuC,CAC1C,WAD0C,EAC7B,WAD6B,CADvCA,EAEU,CAAe,SAAf,EAA0B,UAA1B,CAFVA,EAEoC,CACvC,UADuC,EAC3B,WAD2B,CAFpCA,EAGS,CAAe,UAAf,EAA2B,eAA3B,CAHTA,EAGoC,CACvC,YADuC,EACzB,eADyB,CAHpCA,EAIW,CAAmB,YAAnB,EAAiC,YAAjC,CAJXA,EAI4C,CAC/C,UAD+C,EACnC,WADmC,CAJ5CA,EAKS,CAAe,WAAf,EAA4B,YAA5B,CALTA,EAKqC,CACxC,cADwC,EACxB,eADwB,CALrCA,EAMa,CAAmB,SAAnB,EAA8B,UAA9B,CANbA,CAlBN;AAAA,IAiCaC,cACV,MADUA,EACF,SADEA,GACF,CAAa,SAAb,EAAwB,SAAxB,CADEA,EACsB,CAAa,MAAb,EAAqB,UAArB,CADtBA,EAC2C,CACrD,UADqD,EACzC,UADyC,CAD3CA,EAEE,CAAc,MAAd,EAAsB,cAAtB,CAFFA,EAEwB,CAClC,cADkC,EAClB,WADkB,CAFxBA,EAGM,CAAe,WAAf,EAA4B,WAA5B,CAHNA,EAGkC,CAC5C,cAD4C,EAC5B,SAD4B,CAHlCA,EAIM,CAAa,SAAb,EAAwB,UAAxB,CAJNA,EAI8B,CACxC,UADwC,EAC5B,WAD4B,CAJ9BA,EAKE,CAAe,MAAf,EAAuB,eAAvB,CALFA,EAKyB,CACnC,eADmC,EAClB,YADkB,CALzBA,EAMO,CAAgB,YAAhB,EAA8B,YAA9B,CANPA,EAMqC,CAC/C,eAD+C,EAC9B,UAD8B,CANrCA,EAOO,CAAc,UAAd,EAA0B,WAA1B,CAPPA,EAOiC,CAC3C,WAD2C,EAC9B,YAD8B,CAPjCA,CAjCb;AAAA,IA4CaC,uBAAuBF,mBAAmBvE,GAAnBuE,CAChC,UAACX,CAAD,EAACA;AAAAA,MAACc,QAADd;AAAAA,MAAae,QAAbf;AAA6B,UAAEO,QAAQO,CAARP,CAAF,EAAuBA,QAAQQ,CAARR,CAAvB;AAA+BQ,CAD7BJ,CA5CpC;AAAA,IA+CaK,gBACX,WADWA,EAEX,YAFWA,EAGX,uBAHWA,EAIX,sBAJWA,EAKX,sBALWA,EAMX,sBANWA,EAOX,sBAPWA,EAQX,qBARWA,EASX,qBATWA,EAUX,YAVWA,EAWX,uBAXWA,EAYX,WAZWA,EAaX,aAbWA,EAcX,YAdWA,EAeX,uBAfWA,EAgBX,sBAhBWA,EAiBX,sBAjBWA,EAkBX,sBAlBWA,EAmBX,sBAnBWA,EAoBX,qBApBWA,EAqBX,qBArBWA,EAsBX,YAtBWA,EAuBX,uBAvBWA,EAwBX,WAxBWA,CA/Cb;;ACJA,SAGgBC,cAHhB,CAII5E,CAJJ,EAIe0B,CAJf,EAI0BmD,CAJ1B,EAI4CtE,CAJ5C,EAI4CA;AAC1C;AACEP,OAAGO,EAAQ+C,GAAR/C,CAAYP,CAAZO,EAAemB,CAAfnB,EAAkBsE,CAAlBtE,CADL;AAEEmB,OAAGnB,EAAQ+C,GAAR/C,CAAYP,CAAZO,EAAemB,CAAfnB,EAAkBsE,IAAWb,aAA7BzD;AAFL;AAMF;;AAAA,SAAgBuE,cAAhB,CACIjB,CADJ,EACgBhF,CADhB,EACsC0B,CADtC,EACsCA;AAC7B,MACDoD,mDADC;AAAA,MACA3D,OADA;AAAA,MACG0B,OADH;AAEP;AACEA,OAAGmC,EAAKpB,QAALoB,GAAgBhF,CAAhBgF,GAA+BnC,CADpC;AAEE1B,OAAG6D,EAAKrB,QAALqB,GAAgBhF,CAAhBgF,GAA+B7D;AAFpC;AAMF;;AAAA,SAUgB+E,KAVhB,CAUsBC,CAVtB,EAUiC/B,CAVjC,EAU8CrB,CAV9C,EAU8CA;AAC5C,SAAIoD,IAAI/B,CAAJ+B,GACK/B,CADL+B,GAGAA,IAAIpD,CAAJoD,GACKpD,CADLoD,GAGGA,CANP;AASF;;AAAA,SAAgBC,eAAhB,CACIC,CADJ,EACgBC,CADhB,EAC4BC,CAD5B,EACwCC,CADxC,EACwCA;AACtC,MAAMC,IAAKF,IAAKF,CAAhB;AAAA,MACMK,IAAKF,IAAKF,CADhB;AAEA,SAAOG,IAAKA,CAALA,GAAUC,IAAKA,CAAtB;AAGF;;AAAA,SAAgBC,UAAhB,CAA2BR,CAA3B,EAAwCS,CAAxC,EAAwCA;AACtC;AAAQ/D,OAAGsD,EAAEtD,CAAFsD,GAAMS,EAAE/D,CAAnB;AAAsB1B,OAAGgF,EAAEhF,CAAFgF,GAAMS,EAAEzF;AAAjC;ACjDF;;AAAA,IAMM0F,uBAAsCnB,UAAUxE,GAAVwE,CACxC,UAACZ,CAAD,EAACA;AAAAA,MAACgC,QAADhC;AAAAA,MAAiBiC,QAAjBjC;AACG,UAAEO,QAAQyB,CAARzB,CAAF,EAA2BA,QAAQ0B,CAAR1B,CAA3B;AAAmC0B,CAFCrB,CAN5C;AAAA,IAUMsB,qBACFH,qBAAqB3F,GAArB2F,CAAyB,UAAC/B,CAAD,EAACA;AAAqB;AAAA,CAA/C+B,CAXJ;AAAA,IAaMI,qBACFJ,qBAAqB3F,GAArB2F,CAAyB,UAAC/B,CAAD,EAACA;AAEK;AAAA,CAF/B+B,CAdJ;;AAkBA,SAASK,eAAT,CACIC,CADJ,EACoBC,CADpB,EACqCC,CADrC,EACqCA;AACnC,MAAMC,IAAWD,EAAcjH,KAAdiH,CAAoB,CAApBA,IAAyB,CAA1C;AACA;AACElG,OAAGkG,EAAc5C,GAAd4C,CAAkBD,EAAMjG,CAAxBkG,EAA2BD,EAAMvE,CAAjCwE,EAAoCF,CAApCE,CADL;AAEExE,OAAGwE,EAAc5C,GAAd4C,CAAkBD,EAAMjG,CAAxBkG,EAA2BD,EAAMvE,CAAjCwE,EAAoCC,IAAWH,CAA/CE;AAFL;AAMF;;AAAA,SAASE,wBAAT,CACIH,CADJ,EACqBpH,CADrB,EAC2C+D,CAD3C,EAEIC,CAFJ,EAEIA;AACF;AACE7C,OAAG+E,MAAM7D,KAAKmF,KAALnF,CAAW+E,EAAMjG,CAANiG,GAAUpH,CAArBqC,CAAN6D,EAA0C,CAA1CA,EAA6CnC,IAAS,CAAtDmC,CADL;AAEErD,OAAGqD,MAAM7D,KAAKmF,KAALnF,CAAW+E,EAAMvE,CAANuE,GAAUpH,CAArBqC,CAAN6D,EAA0C,CAA1CA,EAA6ClC,IAAQ,CAArDkC;AAFL;AAaF;;AAAA,SAASuB,wBAAT,CACIN,CADJ,EACoBO,CADpB,EAC8CC,CAD9C,EAEIC,CAFJ,EAEkClG,CAFlC,EAE2D1B,CAF3D,EAGIqH,CAHJ,EAGmCQ,CAHnC,EAGmCA;AAAAA;;AAYjC,OAXM,iBAAC9D,QAAD,EAASC,QAAT,EAMA8D,IACFZ,gBAAgBC,CAAhBD,EAJ0BK,yBAC1BG,EAAeK,QADWR,EACDvH,CADCuH,EACaxD,CADbwD,EACqBvD,CADrBuD,CAI1BL,EAA+CG,CAA/CH,CAPE,EAUFc,IADmBrB,WAAWe,EAAeK,QAA1BpB,EAAoCmB,CAApCnB,CATjB,EAWGtD,IAAI,CAAb,EAAgBA,IAAIwE,CAApB,EAAsCxE,GAAtC,EAA2C;AACzC,QAAM4E,IACFV,yBAAyBS,CAAzBT,EAAyCvH,CAAzCuH,EAAuDxD,CAAvDwD,EAA+DvD,CAA/DuD,CADJ;AAAA,QAGMW,IAAcnC,eAChBkC,EAAsB9G,CADN4E,EACSkC,EAAsBpF,CAD/BkD,EACkC4B,CADlC5B,EAEhBrE,CAFgBqE,CAHpB;AAOAiC,QAAiBrB;AAEX9D,SAAGoF,EAAsBpF,CAAtBoF,GAA0BjI,CAFlB2G;AAGXxF,SAAG8G,EAAsB9G,CAAtB8G,GAA0BjI;AAHlB2G,OAGkB3G;AAE9B6C,SAAGqF,EAAYrF,CAFe7C;AAEZmB,SAAG+G,EAAY/G;AAFHnB,KAHlB2G,CAAjBqB;AAOF;;AAAA,MAAMG,IACFZ,yBAAyBS,CAAzBT,EAAyCvH,CAAzCuH,EAAuDxD,CAAvDwD,EAA+DvD,CAA/DuD,CADJ;AAAA,MAEM7D,IAAQkE,EAAanD,GAAbmD,CACVO,EAAsBhH,CADZyG,EACeO,EAAsBtF,CADrC+E,EACwCD,CADxCC,CAFd;;AAKA;AAAQG,cAAUC,CAAlB;AAAkChD,UAAME,UAAUyC,CAAVzC,CAAxC;AAAqExB;AAArE;AASF;;AAAA,SAAgB0E,UAAhB,CACIC,CADJ,EACyBvE,CADzB,EACiDpC,CADjD,EAEI1B,CAFJ,EAE0BsI,CAF1B,EAGIC,CAHJ,EAGIA;AACF,MAAMC,IAAW1E,EAAO1D,KAAP0D,CAAa,CAAbA,CAAjB;AAAA,MACMwD,IAAWN,mBAAmB5B,MADpC;AAAA,MAGMqD,IAAgC,IAAI/F,KAAJ,CAAU8F,CAAV,CAHtC;AAAA,MAKOE,UALP;AAAA,MAKuBC,WALvB;AAAA,MAMMC,IAAY3C,eAAeyC,CAAfzC,EAAyBjG,CAAzBiG,EAAuCvE,CAAvCuE,CANlB;AAQAwC,IAAkBC,EAASzD,EAA3BwD,IAA2BxD;AACzBvB,WAAOiF,CADkB1D;AAEzBD,UAAME,UAAUwD,EAASzD,EAAnBC,CAFmBD;AAGzB8C,cAAUa;AAHe3D,GAA3BwD;;AAQA,OAAK,IAAII,IAAOvB,IAAW,CAA3B,EAA8BuB,KAAQ,CAAtC,EAAsC,EAAKA,CAA3C,EAAiD;AAC/C,QAAMC,IAAmB9B,mBAAmB6B,CAAnB7B,CAAzB;AAAA,QACMW,IAAmBV,mBAAmB4B,CAAnB5B,CADzB;AAEIwB,MAAkBK,CAAlBL,KAAkBK,CACjBL,EAAkBd,CAAlBc,CADDA,KAEFA,EAAkBd,CAAlBc,IAAsChB,yBAClCoB,CADkCpB,EAC5BgB,EAAkBK,CAAlBL,CAD4BhB,EACSE,CADTF,EAC2B3D,CAD3B2D,EAElC/F,CAFkC+F,EAEzBzH,CAFyByH,EAEXc,CAFWd,CAFpCgB;AAUN;;AAAA,OAASI,IAAO,CAAhB,EAAmBA,IAAOvB,CAA1B,EAA0BA,EAAYuB,CAAtC,EAA4C;AACpCC,QAAmB7B,mBAAmB4B,CAAnB5B,CAAnB6B,EACAnB,IAAmBX,mBAAmB6B,CAAnB7B,CADnB8B;AAEFL,MAAkBK,CAAlBL,KAAkBK,CACjBL,EAAkBd,CAAlBc,CADDA,KAEFA,EAAkBd,CAAlBc,IAAsChB,yBAClCoB,CADkCpB,EAC5BgB,EAAkBK,CAAlBL,CAD4BhB,EACSE,CADTF,EAC2B3D,CAD3B2D,EAElC/F,CAFkC+F,EAEzBzH,CAFyByH,EAEXa,CAFWb,CAFpCgB;AAQN;;AAAA,SAAOA,CAAP;ACjIF;;AAAA,SAISM,mCAJT,CAKIC,CALJ,EAKmBC,CALnB,EAK6CnE,CAL7C,EAMIrB,CANJ,EAMIA;AAAAA,MAD0CZ,OAC1CY;AAAAA,MAD6CtC,OAC7CsC;AACF,SAAOuF,EAAME,IAANF,CAAW,UAAClE,CAAD,EAACA;AAAAA,QACXqE,gBAAkC1F,CAAlC0F,EAA8CpB,QADnCjD;AAEjB,WAAOsB,gBACIjF,CADJiF,EACOvD,CADPuD,EACU+C,EAAsBhI,CADhCiF,EACmC+C,EAAsBtG,CADzDuD,KAEH6C,CAFJ;AAEIA,GAJCD,CAAP;AAYF;;AAAA,SAASI,gBAAT,CACIC,CADJ,EAC2BJ,CAD3B,EAEIR,CAFJ,EAEIA;AAUF,SATkCA,EAAkBnD,MAAlBmD,CAC9B,UAAClD,CAAD,EAAST,CAAT,EAA4BrB,CAA5B,EAA4BA;AAAAA,QAAlBsE,cAAkBtE;AAAAA,QAARC,WAAQD;AAK1B,WAJKsF,oCACGM,CADHN,EACkBE,CADlBF,EACoChB,CADpCgB,EAC8CtF,CAD9CsF,MAEHxD,KAAU7B,CAFPqF,GAIExD,CAAP;AAAOA,GANqBkD,EAO3B,CAP2BA,IASIA,EAAkBrD,MAAxD;AAMF;;AAAA,IAAMkE,sBAAsB,CAA5B;;AAyDA,SAAgBC,mBAAhB,CACI3B,CADJ,EACkC4B,CADlC,EAEIC,CAFJ,EAGIC,CAHJ,EAG4C1J,CAH5C,EAII2J,CAJJ,EAI+BhF,CAJ/B,EAIqDiF,CAJrD,EAIqDA;AAAAA,mBAAtBjF,MAAsBiF,GAAtBjF,iBAAsBiF,MAAtBjF,CAAsBiF;;AAUnD,OATA,IAAMZ,MAAN,EAEMnE,IAAQH,wBACVC,CADUD,EACM4E,mBADN5E,EAC2BkD,CAD3BlD,CAFd,EAKMuE,IAAmBW,IAAYA,CAIrC,EAAOZ,EAAM5D,MAAN4D,GAAeW,CAAfX,IAAeW,CAAsB9E,EAAMgF,KAANhF,EAA5C,GAA2D;AAEzD,QAAMwD,IAAOxD,EAAMiF,OAANjF,EAAb;;AAOA,SAAIkE,oCACIC,CADJD,EACWE,CADXF,EADA9C,eAAeoC,EAAKrD,IAApBiB,EAA0BjG,CAA1BiG,EAAwCuD,CAAxCvD,CACA8C,EAC8CV,EAAKrD,IAALqD,CAAUpD,EADxD8D,CAAJ;AAMA,UAAMgB,IAAY3B,WACdC,CADcD,EACRR,CADQQ,EACMoB,CADNpB,EACqBpI,CADrBoI,EACmCqB,CADnCrB,EAEdsB,CAFctB,CAAlB;AAAA,UAIM1E,IAAQ0F,iBAAiBJ,CAAjBI,EAAwBH,CAAxBG,EAA0CW,CAA1CX,CAJd;AAMAJ,QAAMgB,IAANhB,CAAMgB;AAAMD,oBAANC;AAAiBtG;AAAjBsG,OAANhB;AAAuBtF;AAGzB;;AAAA,SAAOsF,CAAP;ACtIF;;AAAA,SAESiB,GAFT,CAEa9D,CAFb,EAE6BS,CAF7B,EAE6BA;AAC3B,SAAOnG,KAAQ;AACb,QAAMyJ,IAAUlI,IAAOmE,CAAPnE,EAAUmI,OAAUvD,CAAVuD,EAAa,OAAbA,CAAVnI,CAAhB;AAEA,WAAOC,IAAOkE,CAAPlE,EAAUmI,IAAOF,CAAPE,EAAgBD,OAAUvD,CAAVuD,EAAa,OAAbA,CAAhBC,CAAVnI,CAAP;AAA8C,GAHzCxB,CAAP;AAOF;;AAAA,SAAgB4J,QAAhB,CAAyBlK,CAAzB,EAAyBA;AACjB;AAAA,MAAC4D,QAAD;AAAA,MAASC,QAAT;AAAA,MAAgBsG,QAAhB;AAEN,SAAO7J,KAAQ;AACb,QAAM8J,IAAWC,QAAWrK,CAAXqK,EAAWrK,CAAS4D,IAASC,CAAlB7D,EAAyBmK,CAAzBnK,CAAXqK,CAAjB;AAAA,QACMC,IAASC,OAAUH,CAAVG,EAAoB,CAApBA,CADf;AAAA,QAGMC,IAAU5J,WAAciB,IAAOyI,CAAPzI,EAAemI,OAAUnG,CAAVmG,EAAiB,OAAjBA,CAAfnI,CAAdjB,EAAyD,CAAzDA,CAHhB;AAAA,QAIM6J,IAAU7J,WAAckJ,IAAIQ,CAAJR,EAA2BjG,CAA3BiG,CAAdlJ,EAAiD,CAAjDA,CAJhB;AAMA,WAAO8J,QAAWF,CAAXE,EAAoBD,CAApBC,GAA8B,CAA9BA,CAAP;AAAqC,GAPhCpK,CAAP;ACbF;;AAAA,SAIgBqK,mBAJhB,CAKIvJ,CALJ,EAMIwJ,CANJ,EAMIA;AAIF,OAHA,IAAMnG,IAAemG,EAAc3K,KAAd2K,CAAoB,CAApBA,CAArB,EACMxF,IAAS,IAAIyF,YAAJ,CAAiBpG,CAAjB,CADf,EAGSoB,IAAW,CAApB,EAAuBA,IAAWpB,CAAlC,EAAgDoB,GAAhD,EAA4D;AAC1D,QAAM7E,IAAI4J,EAActG,GAAdsG,CAAkB/E,CAAlB+E,EAA4B,CAA5BA,CAAV;AAAA,QACMlI,IAAIkI,EAActG,GAAdsG,CAAkB/E,CAAlB+E,EAA4B,CAA5BA,CADV;AAEAxF,MAAOS,CAAPT,IAAmBhE,EAAckD,GAAdlD,CAAkBJ,CAAlBI,EAAqBsB,CAArBtB,EAAwByE,CAAxBzE,CAAnBgE;AAGF;;AAAA,SAAOA,CAAP;AAGF;;AAAA,SAASQ,gBAAT,CACI5E,CADJ,EACe0B,CADf,EAC0BmD,CAD1B,EAEIwD,CAFJ,EAEIA;AACF;AACErI,OAAGqI,EAAc/E,GAAd+E,CAAkBrI,CAAlBqI,EAAqB3G,CAArB2G,EAAwBxD,CAAxBwD,CADL;AAEE3G,OAAG2G,EAAc/E,GAAd+E,CAAkBrI,CAAlBqI,EAAqB3G,CAArB2G,EAAwBxD,IAAWb,aAAnCqE;AAFL;AAMF;;AAAA,SAAgByB,gBAAhB,CACIC,CADJ,EAEI1B,CAFJ,EAEIA;AAGF,OAFA,IAAMjE,MAAN,EAESS,IAAW,CAApB,EAAuBA,IAAWb,aAAlC,EAAiDa,GAAjD,EAA6D;AAC3D,QAGMlB,qBAHWoG,EAAoBzG,GAApByG,CAAwBlF,CAAxBkF,EAAkC,CAAlCA,EAAqCC,OAArCD,EAGXpG,EAFWoG,EAAoBzG,GAApByG,CAAwBlF,CAAxBkF,EAAkC,CAAlCA,EAAqCC,OAArCD,EAEXpG,EAFgDqG,CAEhDrG,EAFgDqG,CAEhDrG,CAHN;AAAA,QAGOjC,OAHP;AAAA,QAGU1B,OAHV;AAKAoE,MAAOyE,IAAPzE,CAAYpE,CAAZoE,GACAA,EAAOyE,IAAPzE,CAAY1C,CAAZ0C,CADAA;AAIF;;AAAA,SAAO6F,SAAY7F,CAAZ6F,EAAY7F,CAASJ,aAATI,EAAwB,CAAxBA,CAAZ6F,CAAP;AAGF;;AAAA,SAAgBC,eAAhB,CACIH,CADJ,EACsDlL,CADtD,EAEIwJ,CAFJ,EAEIA;AACF,SAAO/I,KAAQ;AACb,QAAM6K,IAAgBL,iBAAiBC,CAAjBD,EAAsCzB,CAAtCyB,CAAtB;AAEA,WAAOM,IACEC,KACGC,IACCP,EAAoBQ,QAApBR,EADDO,EACiCtB,OAAUnK,CAAVmK,EACnC,OADmCA,CADjCsB,CADHD,EAGY,SAHZA,CADFD,EAI0BD,CAJ1BC,CAAP;AAIiCD,GAP5B7K,CAAP;ACVF;;AAAA,SAAsBkL,gBAAtB,CACIpK,CADJ,EACgCG,CADhC,EAEI1B,CAFJ,EAEIA;AAAAA;AAAAA;AAAAA;AAAAA;AAAAA;AAKuB,iBAJrB4L,IAAa,CAAbA,EAEEC,IAAgBxB,SAAS9I,CAAT8I,CAFlBuB,EAE2BrK,IAEAuK,QAAQC,GAARD,CAAQC,CAClCxK,EAAcyK,MAAdzK,EADkCwK,EACVrK,EAAQsK,MAARtK,EADUqK,EACQF,EAAcG,MAAdH,EADRE,CAARD,CAFAvK,CAEN;;AACoCyK;AAQlC,iBATrBC,IAAmBnH,QAAnBmH,EAGArE,IAAeqE,EAAiB,CAAjBA,CAHfA,EAIAzC,IAAgByC,EAAiB,CAAjBA,CAJhBA,EAKAC,IAAsBD,EAAiB,CAAjBA,CALtBA,EAKuC,KAEvCE,IACFd,gBAAgBa,CAAhBb,EAAqCrL,CAArCqL,EAAmD7B,CAAnD6B,CAHyC,EAICW,MAJD,GAIlB;;AAAmBA;AAoB9C,iBApBMI,IAAqBtH,QAArBsH,EAEAC,IACF3J,MAAM4J,IAAN5J,CAAWoI,oBAAoBlD,CAApBkD,EAAkCoB,CAAlCpB,CAAXpI,CAHE0J,EAKArC,IAAYsC,EAAmBnL,GAAnBmL,CAAuB,UAAC3I,CAAD,EAAQD,CAAR,EAAQA;AAE/C,mBADAmI,KAAclI,CAAdkI,EAAclI;AAEZqE;AACE5G,mBAAGiL,EAAmB3H,GAAnB2H,CAAuB3I,CAAvB2I,EAAmC,CAAnCA,CADLrE;AAEElF,mBAAGuJ,EAAmB3H,GAAnB2H,CAAuB3I,CAAvB2I,EAAmC,CAAnCA;AAFLrE,eAFYrE;AAMZsB,oBAAME,UAAUzB,CAAVyB,CANMxB;AAOZA;AAPYA,aACd;AAMEA,WARc2I,CALZD,EAiBNP,EAAchK,OAAdgK,EAjBMO,EAkBND,EAAatK,OAAbsK,EAlBMC,EAkBOvK;AAELkI,wBAFKlI;AAEM6B,mBAAOkI,IAAa7B,EAAU3E;AAFpCvD,YAEb;AAlCE7B;AAkC+CoF,KAlC/CpF;AAkC+CoF,GAlC/CpF;ACzCJ;;AAAA,IAAMuM,qBACF,0EADJ;AAAA,IAEMC,oBACF,yEAHJ;;AAOA,SAAgBC,kBAAhB,CAAmCC,CAAnC,EAAmDC,CAAnD,EAAmDA;AACjD,MAAMC,IAAY,iBAAeF,CAAf,GAAeA,OAAjC;AAEA,SAAmB,MAAfC,CAAe,GACVH,oBAAoB,QAApBA,GAA+BI,CADrB,GAGVJ,oBAAoB,OAApBA,GAA4BG,CAA5BH,GAA4BG,GAA5BH,GAA4CI,CAHrD;AASF;;AAAA,SAAgBC,mBAAhB,CACIH,CADJ,EACoBI,CADpB,EACwCH,CADxC,EACwCA;AACtC,MAAMI;AAAkCC,OAAK,KAAvCD;AAA8CE,SAAM,KAApDF;AAA2DG,QAAM;AAAjEH,GAAN;AAAA,MACMH,IAAY,iBAAeF,CAAf,GAAeA,OADjC;AAGA,SAAmB,MAAfC,CAAe,GACVJ,qBAAqB,QAArBA,GAA8BQ,EAAMD,CAANC,CAA9BR,GAAoCO,GAApCP,GAAqDK,CAD3C,GAGVL,qBAAqB,OAArBA,GAA6BI,CAA7BJ,GAA6BI,GAA7BJ,GAA2CQ,EAAMD,CAANC,CAA3CR,GAAiDO,GAAjDP,GACHK,CAJN;AAIMA;;AAAAA,ICxBFO,iBAAiB,MAAjBA,EAAiB,CAAS,KAA1BA,EAA0B,CAAS,MAAnCA,CDwBEP;AAAAA,ICxBiCQ;AAEzC;AAAA;AASA;;AAAA,SAT4BtL,iBAC1BsL,wCAAgB5M,CAAhB,EAAgBA;AACd,WAAO6M,IAAO7M,CAAP6M,EAAcF,YAAdE,CAAP;AAAqBF,GAFGrL,EAK1BsL,0CAAkBlL,CAAlB,EAAkBA;AACT;AAAA,QAAiBN,QAAjB;AACP;AAAQF,mBAAR;AAAiBD,mBAAjB;AAA0BE,wBAA1B;AAA2CC;AAA3C;AAA2CA,GAPnBE,EAOmBF,CAE/C;AAF+CA,CATN,CAEbrB,SAFa,CDwBjCqM;;ACtBoBrM,SCDnB+M,+BDCmB/M,CCAxB4F,CDAwB5F,ECAbqG,CDAarG,ECAFgN,CDAEhN,ECAFgN;AACxB,SAAQpH,IAAIoH,CAAJpH,IAAqBS,IAAI2G,CAAjC;AAGF;;AAAA,SAAgBC,oBAAhB,CACIzD,CADJ,EAC2BwD,CAD3B,EAC2BA;AACzB,SAAO5H,qBAAqBL,MAArBK,CACH,UAACJ,CAAD,EAAuBT,CAAvB,EAAuBA;AAAAA,QAAC2I,QAAD3I;AAAAA,QAAY4I,QAAZ5I;AACrB,WAAIwI,gCACIvD,EAAU0D,CAAV1D,EAAqBrG,KADzB4J,EACgCvD,EAAU2D,CAAV3D,EAAsBrG,KADtD4J,EAEIC,CAFJD,IAGK/H,CAHL+H,IAMJ/H,EAAOyE,IAAPzE,CAAOyE,CAAMD,EAAU0D,CAAV1D,CAANC,EAA4BD,EAAU2D,CAAV3D,CAA5BC,CAAPzE,GAEOA,CARH+H,CAAJ;AAQO/H,GAVNI,EAUMJ,EAVNI,CAAP;AAcK;;AAAA;AAAA,IAAmBgI,4CAAnB;;AACP,SAAgBC,cAAhB,CAA+B7D,CAA/B,EAA+BA;AAE7B,SAAOA,EAAUzE,MAAVyE,CAAiB,UAACjF,CAAD,EAA2B+I,CAA3B,EAA2BA;AAAAA,QAAzBC,UAAyBD;AAAAA,QAAnBE,UAAmBF;AAAAA,QAAbG,UAAaH;AAAAA,QAAPI,UAAOJ;AAAAA,QAACK,cAADL;AAAAA,QAAYhL,OAAZgL;AAAAA,QAAe1M,OAAf0M;AACjD;AACEC,YAAMzL,KAAKU,GAALV,CAASyL,CAATzL,EAAeQ,CAAfR,CADR;AAEE0L,YAAM1L,KAAKU,GAALV,CAAS0L,CAAT1L,EAAelB,CAAfkB,CAFR;AAGE2L,YAAM3L,KAAK+B,GAAL/B,CAAS2L,CAAT3L,EAAeQ,CAAfR,CAHR;AAIE4L,YAAM5L,KAAK+B,GAAL/B,CAAS4L,CAAT5L,EAAelB,CAAfkB;AAJR;AAIuBlB,GALlB4I,EAKkB5I;AAGvB2M,UAAMK,iBAHiBhN;AAIvB4M,UAAMI,iBAJiBhN;AAKvB6M,UAAML,iBALiBxM;AAMvB8M,UAAMN;AANiBxM,GALlB4I,CAAP;AAeF;;AAAA,SAAgBqE,oBAAhB,CAAqCrE,CAArC,EAAqCA;AAC7B;AAAA,MAACiE,UAAD;AAAA,MAAOC,UAAP;AAAA,MAAaH,UAAb;AAAA,MAAmBC,UAAnB;AACN;AACGlL,OAAGmL,CADN;AACY7M,OAAG8M;AADf,KACeA;AAAQpL,OAAGiL,CAAXG;AAAiB9M,OAAG8M;AAApBA,GADf,EACmCA;AAAQpL,OAAGiL,CAAXG;AAAiB9M,OAAG4M;AAApBE,GADnC,EACuDF;AACpDlL,OAAGmL,CADiDD;AAC3C5M,OAAG4M;AADwCA,GADvD;AAMF;;AAAA,SAAsBM,iBAAtB,CAAwCC,CAAxC,EAAwCA;AAAAA;AAAAA;AAEtC,iBAAOxC,QAAQC,GAARD,CAAYwC,EAAQpN,GAARoN,CAAY;AAAU,iBAAOtC,MAAPuC;AAAOvC,OAA7BsC,CAAZxC,CAAP;AAAgDE,KAFVsC;AAEUtC,GAFVsC;AAKxC;;AAAA,SAAgBE,SAAhB,CACIC,CADJ,EACgBC,CADhB,EACgCC,CADhC,EACgDC,CADhD,EAEIC,CAFJ,EAEIA;AACF,0BAF8CD,KAE9C,GAF8CA,iBAC5CC,KAD4CD,CAE9C,EADEC;AAEAnL,WAAO+K,EAAK/K,KAFZmL;AAGA9E,eAAW0E,EAAK1E,SAAL0E,CAAevN,GAAfuN,CAAmB,UAAC3J,CAAD,EAACA;AAAAA,UAACpB,WAADoB;AAAAA,UAAQE,UAARF;AAAAA,UAAciD,cAAdjD;AAA4B;AAC3BpB,gBAD2B;AAE3BsB,eAF2B;AAG3B+C;AACElF,aAAGkF,EAASlF,CAATkF,GAAa4G,CAAb5G,GAAsB8G,CAD3B9G;AAEE5G,aAAG4G,EAAS5G,CAAT4G,GAAa2G,CAAb3G,GAAsB6G;AAF3B7G;AAH2B;AAKA6G,KALhDH;AAHXI,GACF;AAaF;;AAAA,SAAgBC,UAAhB,CACI9F,CADJ,EACmB0F,CADnB,EACmCC,CADnC,EACmDC,CADnD,EACgEC,CADhE,EACgEA;AAC9D,0BADiDD,KACjD,GADiDA,iBAAaC,KAAbD,CACjD,EAAe,MAAXD,CAAW,IAAgB,MAAXD,CAAL,IAAiC,MAAZE,CAArB,IAAkD,MAAZC,CAAtC,GACN7F,CADM,GAGRA,EAAM9H,GAAN8H,CAAU;AAAQ,qBAAUyF,CAAVD,EAAgBE,CAAhBF,EAAwBG,CAAxBH,EAAgCI,CAAhCJ,EAAyCK,CAAzCL;AAAyCK,GAA3D7F,CAHP;AAMF;;AAAA,SAAgB+F,kBAAhB,CAAmCN,CAAnC,EAA+CO,CAA/C,EAA+CA;AAC7C;AACEtL,WAAO+K,EAAK/K,KADd;AAEEqG,eAAW0E,EAAK1E,SAAL0E,CAAevN,GAAfuN,CACP,UAAC3J,CAAD,EAACA;AAAAA,UAACpB,WAADoB;AAAAA,UAAQE,UAARF;AAAAA,UAAciD,cAAdjD;AAA4B;AAC3BpB,gBAD2B;AAE3BsB,eAF2B;AAG3B+C;AAAWlF,aAAGmM,IAAa,CAAbA,GAAiBjH,EAASlF,CAAxCkF;AAA2C5G,aAAG4G,EAAS5G;AAAvD4G;AAH2B;AAG4B5G,KAJlDsN;AAFb;AAWF;;AAAA,SAAgBQ,mBAAhB,CAAoCjG,CAApC,EAAmDgG,CAAnD,EAAmDA;AACjD,SAAIA,KAAc,CAAdA,GACKhG,CADLgG,GAGGhG,EAAM9H,GAAN8H,CAAU;AAAQ,8BAAmByF,CAAnBM,EAAyBC,CAAzBD;AAAyBC,GAA3ChG,CAHP;AAMF;;AAAA,SAAgBkG,sBAAhB,CACIC,CADJ,EAC6BnP,CAD7B,EAC6BA;AAC3B,SAAIoP,uBAAuBD,CAAvBC,EAAwCpP,CAAxCoP,IACKD,CADLC,GAIG/M,KAAKC,KAALD,CAAW8M,IAAkBnP,CAA7BqC,IAA6CrC,CAA7CqC,GAA4D,CAJnE;AAOF;;AAAA,SAAgBgN,uBAAhB,CAAwCF,CAAxC,EAAwCA;AACtC9O,OAAQC,MAARD,CAC+B,mBAApB8O,CAAoB,IACI,mBAApBA,CAFf9O,EAGI;AAAM,wCAA2B8O,CAA3B,GAA2BA,yDAA3B;AAA2BA,GAHrC9O,GAM+B,mBAApB8O,CAAoB,KAC7B9O,KAAQC,MAARD,CACqC,mBAA1B8O,EAAgBnL,KAD3B3D,EAEI;AAAM,qDACF8O,EAAgBnL,KADd,GACcA,wCADd;AACcA,GAHxB3D,GAIAA,KAAQC,MAARD,CACsC,mBAA3B8O,EAAgBpL,MAD3B1D,EAEI;AAAM,sDACF8O,EAAgBpL,MADd,GACcA,wCADd;AACcA,GAHxB1D,CAL6B,CAN/BA;AAkBF;;AAAA,SAAgBiP,iCAAhB,CACIH,CADJ,EAEInP,CAFJ,EAEIA;AAEF,SADAqP,wBAAwBF,CAAxBE,GAC+B,mBAApBF,CAAoB,GAApBA,CAEPD,uBAAuBC,EAAgBpL,MAAvCmL,EAA+ClP,CAA/CkP,CAFOC,EAGPD,uBAAuBC,EAAgBnL,KAAvCkL,EAA8ClP,CAA9CkP,CAHOC,CAAoB,GAGmBnP,CAI9CkP,uBAAuBC,CAAvBD,EAAwClP,CAAxCkP,CAJ8ClP,EAK9CkP,uBAAuBC,CAAvBD,EAAwClP,CAAxCkP,CAL8ClP,CAHlD;AAaF;;AAAA,IAAMuP,wBAA+C,CAA/CA,EAAkD,EAAlDA,EAAsD,EAAtDA,CAAN;;AACA,SAAgBC,uBAAhB,CAAwCxP,CAAxC,EAAwCA;AACtCK,OAAQC,MAARD,CAC4B,mBAAjBL,CADXK,EACsC;AAAM;AAAA,GAD5CA,GAEAA,KAAQC,MAARD,CACIkP,qBAAqBE,OAArBF,CAA6BvP,CAA7BuP,KAA8C,CADlDlP,EAEI;AAAM,gCAAmBL,CAAnB,GAAmBA,6CAAnB;AAAmBA,GAF7BK,CAFAA;AAQF;;AAAA,SAAS+O,sBAAT,CACIM,CADJ,EACwB1P,CADxB,EACwBA;AACtB,UAAQ0P,IAAa,CAArB,IAA0B1P,CAA1B,IAA2C,CAA3C;AAGF;;AAAA,SAAgB2P,qBAAhB,CACID,CADJ,EACkC1P,CADlC,EACkCA;AAChCK,OAAQC,MAARD,CAC6B,mBAAlBqP,EAAW,CAAXA,CAAkB,IAAqC,mBAAlBA,EAAW,CAAXA,CADhDrP,EAEI;AAAM,uEACFqP,CADE;AACFA,GAHRrP,GAKAA,KAAQC,MAARD,CACI+O,uBAAuBM,EAAW,CAAXA,CAAvBN,EAAsCpP,CAAtCoP,CADJ/O,EAEI;AAAM,0BAAaqP,EAAW,CAAXA,CAAb,GAAwB,gCAAxB,GACC1P,CADD,GACCA,GADD;AACCA,GAHXK,CALAA,EAUAA,KAAQC,MAARD,CACI+O,uBAAuBM,EAAW,CAAXA,CAAvBN,EAAsCpP,CAAtCoP,CADJ/O,EAEI;AAAM,yBAAYqP,EAAW,CAAXA,CAAZ,GAAuB,gCAAvB,GACC1P,CADD,GACCA,GADD;AACCA,GAHXK,CAVAA;AAgBF;;AAAA,SAAgBuP,wBAAhB,CAAyCpP,CAAzC,EAAyCA;AAEvC,SAAOA,aAAiBqP,MAAjBrP,GAAiBqP,CAAarP,EAAMJ,KAANI,CAAY,CAAZA,CAAbqP,EAA6BrP,EAAMJ,KAANI,CAAY,CAAZA,CAA7BqP,CAAjBrP,GAA0D,CAC5BA,EAAMuD,MADsB,EACdvD,EAAMwD,KADQ,CAAjE;AAIF;;AAAA,SAAgB8L,aAAhB,CAA8BtP,CAA9B,EAA8BA;AAC5B,SAAOA,aAAiBqP,MAAjBrP,GAA6BA,CAA7BA,GAAqCuP,QAAWC,UAAXD,CAAsBvP,CAAtBuP,CAA5C;AAGF;;AAAA,SAcgBE,cAdhB,CAeIzP,CAfJ,EAeyBsE,CAfzB,EAeyBA;AAAAA,MAACoL,QAADpL;AAAAA,MAAUqL,QAAVrL;AAAAA,MAEjB+I,+BAFiB/I;AAAAA,MAEhBf,QAFgBe;AAAAA,MAERd,QAFQc;AAAAA,MAGjBsL,IAAeD,IAAUD,CAHRpL;AAAAA,MAKnBoJ,gBALmBpJ;AAAAA,MAKlBuL,QALkBvL;AAAAA,MAKZwL,QALYxL;AAAAA,MAKNyL,QALMzL;AAAAA,MAKA0L,QALA1L;AA2BvB,SAvBed,IAAQD,CAARC,GAEFoM,CAFEpM,IAIbqM,IAAO,CAAPA,EACAC,IAAO,CADPD,EAEAE,IAAOlO,KAAKmF,KAALnF,CAAW,MAAO+N,IAAerM,CAAfqM,GAAwBpM,CAA/B,CAAX3B,CAFPgO,EAGAG,IAAOnO,KAAKmF,KAALnF,CAAW,MAAO+N,IAAerM,CAAfqM,GAAwBpM,CAA/B,CAAX3B,CAPM2B,KAUbqM,IAAOhO,KAAKmF,KAALnF,CAAW,MAAQ,IAAM+N,CAAN,GAAsBpM,CAAtB,GAA8BD,CAAtC,CAAX1B,CAAPgO,EACAC,IAAOjO,KAAKmF,KAALnF,CAAW,MAAQ,IAAM+N,CAAN,GAAsBpM,CAAtB,GAA8BD,CAAtC,CAAX1B,CADPgO,EAEAE,IAAO,CAFPF,EAGAG,IAAO,CAbMxM,GAaN;AAUDyM,aAPqBhQ,KAAQ;AACnC,UAAIiQ,IAAcZ,cAActP,CAAdsP,CAAlB;AAGA,aAFAY,IAAcC,MAASD,CAATC,EAASD,EAAeL,CAAfK,EAAqBJ,CAArBI,GAAqBJ,CAAQC,CAARD,EAAcE,CAAdF,CAArBI,EAAmCF,CAAQ,CAARA,EAAW,CAAXA,CAAnCE,CAATC,CAAdD,EAEOE,MAASC,cAATD,CAAwBF,CAAxBE,EAAwBF,CAAcR,CAAdQ,EAAuBP,CAAvBO,CAAxBE,CAAP;AAAsDT,KAJ3B1P,CAHpB;AAUQqQ;AAAUC,WAAKV,CAAfS;AAAqBE,YAAMT,CAA3BO;AAAiCG,aAAOT,CAAxCM;AAA8CI,cAAQZ;AAAtDQ;AAVR,GAUT;AAGF;;AAAA,SAAgBK,iBAAhB,CACInI,CADJ,EACmBlE,CADnB,EAEI+I,CAFJ,EAGIiD,CAHJ,EAGsBM,CAHtB,EAGsBA;AAAAA,MAFFrN,QAEEqN;AAAAA,MAFMpN,QAENoN;AAAAA,MADjBC,QACiBD;AAAAA,MADME,QACNF;AAAAA,MAMdG,IACFzC,WAAW9F,CAAX8F,EAAW9F,CALVjF,IAAS+M,EAAQC,GAAjBhN,GAAuB+M,EAAQI,MAKrBlI,IALqBkI,CAKhCpC,EALgCoC,CAE/BlN,IAAQ8M,EAAQE,IAAhBhN,GAAuB8M,EAAQG,KAFAC,IAEAD,CAGhCnC,EAHgCmC,CAGGH,EAAQC,GAA3CjC,EAA2CiC,CAAMD,EAAQE,IAAzDlC,CAPgBsC;AASpB,SAAIA,IACKnC,oBAAoBsC,CAApBtC,EAAiCjL,CAAjCiL,CADLmC,GAGKG,CAHT;AC9KF;;AAAA,IAAMC;AACJC,gBAAc,aADVD;AAEJxR,gBAAc,EAFVwR;AAGJ1E,cAAY,GAHR0E;AAIJrC,mBAAiB;AAJbqC,CAAN;AAAA,IAOME,sBAAsB,aAAtBA,EAAqC,UAArCA,CAPN;AAAA,IAQMC;AACJC,gBAAgB,CAAhBA,EAAmB,EAAnBA,EAAuB,EAAvBA,CADID;AAEJE,aAAa,EAAbA,EAAiB,EAAjBA;AAFIF,CARN;AAAA,IAaMG;AACJF,gBAAgB,EAAhBA,EAAsB,GAAtBA,EAA4B,CAA5BA,CADIE;AAEJD,aAAa,CAAbA;AAFIC,CAbN;AAAA,IAiBMC,qBAAqB,CAArBA,EAAwB,CAAxBA,EAA2B,CAA3BA,CAjBN;;AAmBA,SAASC,mBAAT,CAA6BC,CAA7B,EAA6BA;AAM3B,MAH2B,SAF3BA,IAASA,KAAUT,mBAEQ,EAAhBC,YAAgB,KACzBQ,EAAOR,YAAPQ,GAAsB,aADG,GAGvBP,mBAAmBjC,OAAnBiC,CAA2BO,EAAOR,YAAlCC,IAAkD,CAAtD,EACE,MAAM,IAAIQ,KAAJ,CACF,0BAAwBD,EAAOR,YAA/B,GAA+BA,qBAA/B,GACoBC,kBAFlB,CAAN;AAcF,MAT8B,QAA1BO,EAAO9C,eAAmB,KAC5B8C,EAAO9C,eAAP8C,GAAyB,GADG,GAI9B5C,wBAAwB4C,EAAO9C,eAA/BE,CAJ8B,EAMH,QAAvB4C,EAAOjS,YAAgB,KACzBiS,EAAOjS,YAAPiS,GAAsB,EADG,CANG,EAS1BN,aAAaM,EAAOR,YAApBE,EAAkClC,OAAlCkC,CAA0CM,EAAOjS,YAAjD2R,IAAiE,CAArE,EACE,MAAM,IAAIO,KAAJ,CACF,0BAAwBD,EAAOjS,YAA/B,GAA+BA,qBAA/B,GACoB2R,aAAaM,EAAOR,YAApBE,CADpB,GACwCF,oBADxC,GAEoBQ,EAAOR,YAF3B,GAE2BA,GAHzB,CAAN;AASF,MAHyB,QAArBQ,EAAOnF,UAAc,KACvBmF,EAAOnF,UAAPmF,GAAoB,CADG,GAGrBH,iBAAiBG,EAAOR,YAAxBK,EAAsCrC,OAAtCqC,CAA8CG,EAAOnF,UAArDgF,IAAmE,CAAvE,EACE,MAAM,IAAII,KAAJ,CACF,wBAAsBD,EAAOnF,UAA7B,GAA6BA,qBAA7B,GACoBgF,iBAAiBG,EAAOR,YAAxBK,CADpB,GAC4CL,oBAD5C,GAEoBQ,EAAOR,YAF3B,GAE2BA,GAHzB,CAAN;AASF,MAHyB,QAArBQ,EAAOtF,UAAc,KACvBsF,EAAOtF,UAAPsF,GAAoB,CADG,GAGrBF,kBAAkBtC,OAAlBsC,CAA0BE,EAAOtF,UAAjCoF,IAA+C,CAAnD,EACE,MAAM,IAAIG,KAAJ,CACF,wBAAsBD,EAAOtF,UAA7B,GAA6BA,qBAA7B,GACoBoF,iBADpB,GACoBA,oBADpB,GAEoBE,EAAOR,YAF3B,GAE2BA,GAHzB,CAAN;AAMF,MAA4B,kBAAxBQ,EAAOR,YAAiB,IAAyC,OAAxBQ,EAAOjS,YAAxB,IACF,MAAtBiS,EAAOnF,UADX,EAEE,MAAM,IAAIoF,KAAJ,CACF,yEADE,CAAN;AAKF,SAAOD,CAAP;AAkDF;;AAAA,IAAaE;AACXf,mBAAgB;AADLe,CAAb;AAAA,IAIaC;AACXhB,mBAAgB,CADLgB;AAEXC,iBAAe,CAFJD;AAGXzN,kBAAgB,EAHLyN;AAIXxI,aAAW;AAJAwI,CAJb;;AAWA,SAGSE,8BAHT,CAGwCL,CAHxC,EAGwCA;AAC/B;AAAA,MAAetN,oBAAf;AAAA,MAA+BiF,eAA/B;AAEP,MAAIyI,KAAiB,CAArB,EACE,MAAM,IAAIH,KAAJ,CACF,2BAAyBG,CAAzB,GAAyBA,iBADvB,CAAN;AAKF,MAAI1N,IAAiB,CAAjBA,IAAwBA,IAAiB,CAA7C,EACE,MAAM,IAAIuN,KAAJ,CACF,4BAA0BvN,CAA1B,GAA0BA,iCADxB,CAAN;AAKF,MAAIiF,KAAa,CAAjB,EACE,MAAM,IAAIsI,KAAJ,CAAU,uBAAqBtI,CAArB,GAAqBA,GAA/B,CAAN;AAIJ;;AAAA;AAIE,aAAY2I,CAAZ,EAA4BpD,CAA5B,EAA4BA;AAC1BK,4BAAwB+C,EAAIvS,YAA5BwP,GACAG,sBAAsBR,CAAtBQ,EAAuC4C,EAAIvS,YAA3C2P,CADAH,EAGAvP,KAAKuS,SAALvS,GAAiBsS,CAHjB/C,EAIAvP,KAAKkP,eAALlP,GAAuBkP,CAJvBK;AA8IJ;;AAAA,SAnHQiD,oCAAN,UACIjS,CADJ,EAEIyR,CAFJ,EAEIA;AAAAA;AAAAA;;AAAAA;AAAAA;AAAAA;AAmBuB,mBAjBnBS,iBACDN,6BADCM,EAEDT,CAFCS,GAKNJ,+BAA+BL,CAA/BK,CALMI,EAOA1S,IAAeC,KAAKuS,SAALvS,CAAeD,YAP9B0S,EAQAvD,IAAkBlP,KAAKkP,eARvBuD,EAUA5N,IAAkB8K,yBAAyBpP,CAAzBoP,CAVlB8C,EAUC3O,QAVD2O,EAUS1O,QAVT0O,EAYA7E,IAAqBoC,eAAezP,CAAfyP,EAAsBd,CAAtBc,CAZrByC,EAYCjC,aAZDiC,EAYU5B,aAZV4B,EAcAxE,IACFjO,KAAKuS,SAALvS,CAAegB,OAAfhB,CAAuBwQ,CAAvBxQ,CAfEyS,EAcCnR,mBAdDmR,EAcgBhR,aAdhBgR,EAcyB/Q,qBAdzB+Q,EAc0C9Q,qBAd1C8Q,EAc0C9Q,IAGjByM,mBAC1B9M,CAD0B8M,EACX3M,CADW2M,EACF1M,CADE0M,EACezM,CADfyM,EAHiBzM,CAGvB;;AACqBA;AAOhC,mBARRqK,IAAmB0G,QAAnB1G,EAGArE,IAAeqE,EAAiB,CAAjBA,CAHfA,EAIAzC,IAAgByC,EAAiB,CAAjBA,CAJhBA,EAKAxC,IAAyBwC,EAAiB,CAAjBA,CALzBA,EAMAvC,IAAyBuC,EAAiB,CAAjBA,CANzBA,EAM0C,IAE5B1C,oBAChB3B,CADgB2B,EACFC,CADED,EACaE,CADbF,EAEhBG,CAFgBH,EAEQvJ,CAFRuJ,EAEsBmJ,EAAmBL,aAFzC9I,EAGhBmJ,EAAmB/N,cAHH4E,EAGmBmJ,EAAmB9I,SAHtCL,CAF4B,CAElC;;AAG4CK;AAY1D,mBAfMZ,IAAQ2J,QAAR3J,EAKA4J,IAAczB,kBAChBnI,CADgBmI,EAChBnI,CAAQjF,CAARiF,EAAgBhF,CAAhBgF,CADgBmI,EACQhC,CADRgC,EACyBL,CADzBK,EAEhBuB,EAAmBtB,cAFHD,CALdnI,EASNzH,EAAcM,OAAdN,EATMyH,EAUNtH,EAAQG,OAARH,EAVMsH,EAWNrH,EAAgBE,OAAhBF,EAXMqH,EAYNpH,EAAgBC,OAAhBD,EAZMoH,EAaNyH,EAAQ5O,OAAR4O,EAbMzH,EAaEnH,IAED+Q,CAFC/Q,CAER;AA1CEoQ;AA0CKW,OA1CLX;AA0CKW,KA1CLX;AA0CKW,GA5CHH,EAiEAA,iCAAN,UACIjS,CADJ,EAEIyR,CAFJ,EAEIA;AAAAA;AAAAA;;AAAAA;AAAAA;AAAAA;AAgBW,mBAdPS,iBAAyBP,8BAAzBO,EAA4DT,CAA5DS,GAIA1S,IAAeC,KAAKuS,SAALvS,CAAeD,YAJ9B0S,EAKAvD,IAAkBlP,KAAKkP,eALvBuD,EAOA5N,IAAkB8K,yBAAyBpP,CAAzBoP,CAPlB8C,EAOC3O,QAPD2O,EAOS1O,QAPT0O,EASA7E,IAAqBoC,eAAezP,CAAfyP,EAAsBd,CAAtBc,CATrByC,EASCjC,aATDiC,EASU5B,aATV4B,EAWAxE,IACFjO,KAAKuS,SAALvS,CAAegB,OAAfhB,CAAuBwQ,CAAvBxQ,CAZEyS,EAWCnR,mBAXDmR,EAWgBhR,aAXhBgR,EAWyB/Q,qBAXzB+Q,EAW0C9Q,qBAX1C8Q,EAW0C9Q,IAG7B+J,iBAAiBpK,CAAjBoK,EAAgCjK,CAAhCiK,EAAyC3L,CAAzC2L,CAH6B/J,CAGnC;;AAA+C5B;AAa5D,mBAbMyO,IAAOkE,QAAPlE,EAGAmE,IAAczB,mBAFL1C,CAEK0C,GAFL1C,CAGH1K,CAHG0K,EAGKzK,CAHLyK,CAEK0C,EACQhC,CADRgC,EACyBL,CADzBK,EAEhBuB,EAAmBtB,cAFHD,CAHd1C,EAONlN,EAAcM,OAAdN,EAPMkN,EAQN/M,EAAQG,OAARH,EARM+M,EASN9M,EAAgBE,OAAhBF,EATM8M,EAUN7M,EAAgBC,OAAhBD,EAVM6M,EAWNgC,EAAQ5O,OAAR4O,EAXMhC,EAWE5M,IAED+Q,EAAY,CAAZA,CAFC/Q,CAER;AA7BEoQ;AA6BiB,OA7BjBA;AA6BiB,KA7BjBA;AA6BiB,GAhGfQ,EAoGAA,4BAAN,UACIjS,CADJ,EAEIyR,CAFJ,EAEIA;AAAAA;AAAAA;AAAAA;AAAAA;AAAAA,mBAE4B,oBAA1BA,EAAOY,cAAmB,GAAnBA,MAAmB,GAAnBA,IACU5S,KAAK6S,kBAAL7S,CAAwBO,CAAxBP,EAA+BgS,CAA/BhS,CADV4S,CAFTZ;;AAGkDA;AAClD,wBADanN,QACb;;AADaA;AAGb,uBAAO7E,KAAK8S,qBAAL9S,CAA2BO,CAA3BP,EAAkCgS,CAAlChS,CAAP;AANAgS;AAMyCA,OANzCA;AAMyCA,KANzCA;AAMyCA,GA5GvCQ,EAgHCA,sBAAP;AACExS,SAAKuS,SAALvS,CAAe4B,OAAf5B;AAAe4B,GAjHX4Q,EAiHW5Q,CAEnB;AAFmBA,CAjJnB;;AAiJmBA,SAIJmR,aAJInR,CAIUoQ,CAJVpQ,EAIUoQ;AAAAA;AAAAA;AAAAA;AAAAA;AAAAA;AAI3B,cAHMjS,IAAeiS,EAAOjS,YAAtBA,EACA2M,IAAasF,EAAOtF,UADpB3M,EAEA8M,IAAamF,EAAOnF,UAFpB9M,EAGI,QAANiT,EAAJ,EACE,MAAM,IAAIf,KAAJ,CACF,gJADE,CAAN;AAOiB,iBADbgB,IAAMrG,oBAAoB7M,CAApB6M,EAAkCC,CAAlCD,EAA8CF,CAA9CE,CAANqG,EAAoDvG,IACjCwG,eAAsBlB,EAAOmB,QAAPnB,IAAmBiB,CAAzCC,CADiCxG,CACvC;;AAA+CuG;AAMlE,iBANMG,IAAavO,QAAbuO,EACAC,IAAY,IAAIvR,SAAJ,CAAcsR,CAAd,EAA0BrT,CAA1B,CADZqT,EAGAE,IAAuBjE,kCACzB2C,EAAO9C,eADkBG,EACDgE,EAAUtT,YADTsP,CAHvB+D,EAIgCrT,IAE/B,IAAIyS,OAAJ,CAAYa,CAAZ,EAAuBC,CAAvB,CAF+BvT,CAEtC;AAlB2BiS;AAkBGsB,KAlBHtB;AAkBGsB,GAlBHtB;AAqB7B;;AAAA,SAAeuB,UAAf,CAA0BvB,CAA1B,EAA0BA;AAAAA;AAAAA;AAAAA;AAAAA;AAAAA;AAGxB,cAFMjS,IAAeiS,EAAOjS,YAAtBA,EACA2M,IAAasF,EAAOtF,UADpB3M,EAEI,QAANiT,EAAJ,EACE,MAAM,IAAIf,KAAJ,CACF,gJADE,CAAN;AAOiB,iBADbgB,IAAMzG,mBAAmBzM,CAAnByM,EAAiCE,CAAjCF,CAANyG,EAAuCvG,IACpBwG,eAAsBlB,EAAOmB,QAAPnB,IAAmBiB,CAAzCC,CADoBxG,CAC1B;;AAA+CuG;AAIlE,iBAJMG,IAAavO,QAAbuO,EACAI,IAAS,IAAIrG,MAAJ,CAAWiG,CAAX,EAAuBrT,CAAvB,CADTqT,EAEAE,IAAuBjE,kCACzB2C,EAAO9C,eADkBG,EACDmE,EAAOzT,YADNsP,CAFvB+D,EAG6BrT,IAC5B,IAAIyS,OAAJ,CAAYgB,CAAZ,EAAoBF,CAApB,CAD4BvT,CACnC;AAfwBiS;AAeGsB,KAfHtB;AAeGsB,GAfHtB;AA8B1B;;AAAA,SAAsByB,IAAtB,CAA2BzB,CAA3B,EAA2BA;AAAAA;AAAAA;AAGzB,aAA4B,gBAD5BA,IAASD,oBAAoBC,CAApBD,CACmB,EAAjBP,YAAiB,GAAjBA,IACF+B,WAAWvB,CAAXuB,CADE/B,CAAiB,GAEO,kBAAxBQ,EAAOR,YAAiB,GAAjBA,IACTuB,cAAcf,CAAde,CADSvB,CAAiB,GACZQ,IAEd,IAFcA,CAHvB;AAKS,KARgBA;AAQhB,GARgBA;AC3b3B;;AAAA,IAAM0B,UAAU,OAAhB;AAAgB","names":["model","outputStride","this","inputShape","inputs","shape","tf.util","assert","BaseModel","input","tf.tidy","asFloat","_this","preprocessInput","tf.cast","asBatch","tf.expandDims","results3d","predict","map","y","tf.squeeze","namedResults","nameOutputResults","heatmapScores","tf.sigmoid","heatmap","offsets","displacementFwd","displacementBwd","dispose","tslib_1.__extends","MobileNet","tf.div","tf.sub","results","half","k","Math","floor","maxSize","getElementValue","priorityQueue","Array","numberOfElements","MaxHeap","x","swim","max","exchange","sink","slice","less","j","i","getValueAt","t","scoreIsMaximumInLocalWindow","keypointId","score","heatmapY","heatmapX","localMaximumRadius","scores","height","width","localMaximum","yStart","yEnd","min","yCurrent","xStart","xEnd","xCurrent","get","buildPartWithScoreQueue","scoreThreshold","numKeypoints","queue","_a","enqueue","part","id","partNames","NUM_KEYPOINTS","length","partIds","reduce","result","jointName","connectedPartNames","poseChain","connectedPartIndices","jointNameA","jointNameB","partChannels","getOffsetPoint","keypoint","getImageCoords","clamp","a","squaredDistance","y1","x1","y2","x2","dy","dx","addVectors","b","parentChildrenTuples","parentJoinName","childJoinName","parentToChildEdges","childToParentEdges","getDisplacement","edgeId","point","displacements","numEdges","getStridedIndexNearPoint","round","traverseToTargetKeypoint","sourceKeypoint","targetKeypointId","scoresBuffer","offsetRefineStep","displacement","position","targetKeypoint","targetKeypointIndices","offsetPoint","targetKeyPointIndices","decodePose","root","displacementsFwd","displacementsBwd","numParts","instanceKeypoints","rootPart","rootScore","rootPoint","edge","sourceKeypointId","withinNmsRadiusOfCorrespondingPoint","poses","squaredNmsRadius","some","correspondingKeypoint","getInstanceScore","existingPoses","kLocalMaximumRadius","decodeMultiplePoses","offsetsBuffer","displacementsFwdBuffer","displacementsBwdBuffer","maxPoseDetections","nmsRadius","empty","dequeue","keypoints","push","mod","floored","tf.scalar","tf.mul","argmax2d","depth","reshaped","tf.reshape","coords","tf.argMax","yCoords","xCoords","tf.concat","getPointsConfidence","heatMapCoords","Float32Array","getOffsetVectors","heatMapCoordsBuffer","valueOf","tf.tensor2d","getOffsetPoints","offsetVectors","tf\r\n            .add","tf\r\n            .cast","tf\r\n            .mul","toTensor","decodeSinglePose","totalScore","heatmapValues","Promise","all","buffer","allTensorBuffers","heatmapValuesBuffer","offsetPoints","offsetPointsBuffer","keypointConfidence","from","MOBILENET_BASE_URL","RESNET50_BASE_URL","resNet50Checkpoint","stride","quantBytes","graphJson","mobileNetCheckpoint","multiplier","toStr","1","0.75","0.5","imageNetMean","ResNet","tf.add","eitherPointDoesntMeetConfidence","minConfidence","getAdjacentKeyPoints","leftJoint","rightJoint","POSITIVE_INFINITY","getBoundingBox","_b","maxX","maxY","minX","minY","_c","NEGATIVE_INFINITY","getBoundingBoxPoints","toTensorBuffers3D","tensors","tensor","scalePose","pose","scaleY","scaleX","offsetY","offsetX","scalePoses","flipPoseHorizontal","imageWidth","flipPosesHorizontal","toValidInputResolution","inputResolution","isValidInputResolution","validateInputResolution","getValidInputResolutionDimensions","VALID_OUTPUT_STRIDES","assertValidOutputStride","indexOf","resolution","assertValidResolution","getInputTensorDimensions","tf.Tensor","toInputTensor","tf.browser","fromPixels","padAndResizeTo","targetH","targetW","targetAspect","padT","padB","padL","padR","resized","imageTensor","tf.pad3d","tf.image","resizeBilinear","padding","top","left","right","bottom","scaleAndFlipPoses","flipHorizontal","inputResolutionHeight","inputResolutionWidth","scaledPoses","MOBILENET_V1_CONFIG","architecture","VALID_ARCHITECTURE","VALID_STRIDE","MobileNetV1","ResNet50","VALID_MULTIPLIER","VALID_QUANT_BYTES","validateModelConfig","config","Error","SINGLE_PERSON_INFERENCE_CONFIG","MULTI_PERSON_INFERENCE_CONFIG","maxDetections","validateMultiPersonInputConfig","net","baseModel","PoseNet","configWithDefaults","_d","resultPoses","decodingMethod","estimateSinglePose","estimateMultiplePoses","loadMobileNet","tf","url","tfconv.loadGraphModel","modelUrl","graphModel","mobilenet","validInputResolution","loadResNet","resnet","load","version"],"sources":["C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\base_model.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\mobilenet.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\multi_pose\\max_heap.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\multi_pose\\build_part_with_score_queue.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\keypoints.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\multi_pose\\util.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\multi_pose\\decode_pose.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\multi_pose\\decode_multiple_poses.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\single_pose\\argmax2d.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\single_pose\\util.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\single_pose\\decode_single_pose.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\checkpoints.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\resnet.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\util.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\posenet_model.ts","C:\\Users\\bulga\\poseswordvideo\\node_modules\\@tensorflow-models\\posenet\\src\\version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\nimport {PoseNetOutputStride} from './types';\n\n/**\n * PoseNet supports using various convolution neural network models\n * (e.g. ResNet and MobileNetV1) as its underlying base model.\n * The following BaseModel interface defines a unified interface for\n * creating such PoseNet base models. Currently both MobileNet (in\n * ./mobilenet.ts) and ResNet (in ./resnet.ts) implements the BaseModel\n * interface. New base models that conform to the BaseModel interface can be\n * added to PoseNet.\n */\nexport abstract class BaseModel {\n  constructor(\n      protected readonly model: tfconv.GraphModel,\n      public readonly outputStride: PoseNetOutputStride) {\n    const inputShape =\n        this.model.inputs[0].shape as [number, number, number, number];\n    tf.util.assert(\n        (inputShape[1] === -1) && (inputShape[2] === -1),\n        () => `Input shape [${inputShape[1]}, ${inputShape[2]}] ` +\n            `must both be equal to or -1`);\n  }\n\n  abstract preprocessInput(input: tf.Tensor3D): tf.Tensor3D;\n\n  /**\n   * Predicts intermediate Tensor representations.\n   *\n   * @param input The input RGB image of the base model.\n   * A Tensor of shape: [`inputResolution`, `inputResolution`, 3].\n   *\n   * @return A dictionary of base model's intermediate predictions.\n   * The returned dictionary should contains the following elements:\n   * heatmapScores: A Tensor3D that represents the heatmapScores.\n   * offsets: A Tensor3D that represents the offsets.\n   * displacementFwd: A Tensor3D that represents the forward displacement.\n   * displacementBwd: A Tensor3D that represents the backward displacement.\n   */\n  predict(input: tf.Tensor3D): {\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  } {\n    return tf.tidy(() => {\n      const asFloat = this.preprocessInput(tf.cast(input, 'float32'));\n      const asBatch = tf.expandDims(asFloat, 0);\n      const results = this.model.predict(asBatch) as tf.Tensor4D[];\n      const results3d: tf.Tensor3D[] = results.map(y => tf.squeeze(y, [0]));\n\n      const namedResults = this.nameOutputResults(results3d);\n\n      return {\n        heatmapScores: tf.sigmoid(namedResults.heatmap),\n        offsets: namedResults.offsets,\n        displacementFwd: namedResults.displacementFwd,\n        displacementBwd: namedResults.displacementBwd\n      };\n    });\n  }\n\n  // Because MobileNet and ResNet predict() methods output a different order for\n  // these values, we have a method that needs to be implemented to order them.\n  abstract nameOutputResults(results: tf.Tensor3D[]): {\n    heatmap: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  };\n\n  /**\n   * Releases the CPU and GPU memory allocated by the model.\n   */\n  dispose() {\n    this.model.dispose();\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {BaseModel} from './base_model';\n\nexport class MobileNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    // Normalize the pixels [0, 255] to be between [-1, 1].\n    return tf.tidy(() => tf.sub(tf.div(input, 127.5), 1.0));\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [offsets, heatmap, displacementFwd, displacementBwd] = results;\n    return {offsets, heatmap, displacementFwd, displacementBwd};\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// algorithm based on Coursera Lecture from Algorithms, Part 1:\n// https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort\n\nfunction half(k: number) {\n  return Math.floor(k / 2);\n}\n\nexport class MaxHeap<T> {\n  private priorityQueue: T[];\n  private numberOfElements: number;\n  private getElementValue: (element: T) => number;\n\n  constructor(maxSize: number, getElementValue: (element: T) => number) {\n    this.priorityQueue = new Array(maxSize);\n    this.numberOfElements = -1;\n    this.getElementValue = getElementValue;\n  }\n\n  public enqueue(x: T): void {\n    this.priorityQueue[++this.numberOfElements] = x;\n    this.swim(this.numberOfElements);\n  }\n\n  public dequeue(): T {\n    const max = this.priorityQueue[0];\n    this.exchange(0, this.numberOfElements--);\n    this.sink(0);\n    this.priorityQueue[this.numberOfElements + 1] = null;\n    return max;\n  }\n\n  public empty(): boolean {\n    return this.numberOfElements === -1;\n  }\n\n  public size(): number {\n    return this.numberOfElements + 1;\n  }\n\n  public all(): T[] {\n    return this.priorityQueue.slice(0, this.numberOfElements + 1);\n  }\n\n  public max(): T {\n    return this.priorityQueue[0];\n  }\n\n  private swim(k: number): void {\n    while (k > 0 && this.less(half(k), k)) {\n      this.exchange(k, half(k));\n      k = half(k);\n    }\n  }\n\n  private sink(k: number): void {\n    while (2 * k <= this.numberOfElements) {\n      let j = 2 * k;\n      if (j < this.numberOfElements && this.less(j, j + 1)) {\n        j++;\n      }\n      if (!this.less(k, j)) {\n        break;\n      }\n      this.exchange(k, j);\n      k = j;\n    }\n  }\n\n  private getValueAt(i: number): number {\n    return this.getElementValue(this.priorityQueue[i]);\n  }\n\n  private less(i: number, j: number): boolean {\n    return this.getValueAt(i) < this.getValueAt(j);\n  }\n\n  private exchange(i: number, j: number): void {\n    const t = this.priorityQueue[i];\n    this.priorityQueue[i] = this.priorityQueue[j];\n    this.priorityQueue[j] = t;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {PartWithScore, TensorBuffer3D} from '../types';\n\nimport {MaxHeap} from './max_heap';\n\nfunction scoreIsMaximumInLocalWindow(\n    keypointId: number, score: number, heatmapY: number, heatmapX: number,\n    localMaximumRadius: number, scores: TensorBuffer3D): boolean {\n  const [height, width] = scores.shape;\n\n  let localMaximum = true;\n  const yStart = Math.max(heatmapY - localMaximumRadius, 0);\n  const yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);\n  for (let yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {\n    const xStart = Math.max(heatmapX - localMaximumRadius, 0);\n    const xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);\n    for (let xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {\n      if (scores.get(yCurrent, xCurrent, keypointId) > score) {\n        localMaximum = false;\n        break;\n      }\n    }\n    if (!localMaximum) {\n      break;\n    }\n  }\n\n  return localMaximum;\n}\n\n/**\n * Builds a priority queue with part candidate positions for a specific image in\n * the batch. For this we find all local maxima in the score maps with score\n * values above a threshold. We create a single priority queue across all parts.\n */\nexport function buildPartWithScoreQueue(\n    scoreThreshold: number, localMaximumRadius: number,\n    scores: TensorBuffer3D): MaxHeap<PartWithScore> {\n  const [height, width, numKeypoints] = scores.shape;\n\n  const queue = new MaxHeap<PartWithScore>(\n      height * width * numKeypoints, ({score}) => score);\n\n  for (let heatmapY = 0; heatmapY < height; ++heatmapY) {\n    for (let heatmapX = 0; heatmapX < width; ++heatmapX) {\n      for (let keypointId = 0; keypointId < numKeypoints; ++keypointId) {\n        const score = scores.get(heatmapY, heatmapX, keypointId);\n\n        // Only consider parts with score greater or equal to threshold as\n        // root candidates.\n        if (score < scoreThreshold) {\n          continue;\n        }\n\n        // Only consider keypoints whose score is maximum in a local window.\n        if (scoreIsMaximumInLocalWindow(\n                keypointId, score, heatmapY, heatmapX, localMaximumRadius,\n                scores)) {\n          queue.enqueue({score, part: {heatmapY, heatmapX, id: keypointId}});\n        }\n      }\n    }\n  }\n\n  return queue;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport type Tuple<T> = [T, T];\nexport type StringTuple = Tuple<string>;\nexport type NumberTuple = Tuple<number>;\n\nexport const partNames = [\n  'nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\n  'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist',\n  'leftHip', 'rightHip', 'leftKnee', 'rightKnee', 'leftAnkle', 'rightAnkle'\n];\n\nexport const NUM_KEYPOINTS = partNames.length;\n\nexport interface NumberDict {\n  [jointName: string]: number;\n}\n\nexport const partIds =\n    partNames.reduce((result: NumberDict, jointName, i): NumberDict => {\n      result[jointName] = i;\n      return result;\n    }, {}) as NumberDict;\n\nconst connectedPartNames: StringTuple[] = [\n  ['leftHip', 'leftShoulder'], ['leftElbow', 'leftShoulder'],\n  ['leftElbow', 'leftWrist'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['rightHip', 'rightShoulder'],\n  ['rightElbow', 'rightShoulder'], ['rightElbow', 'rightWrist'],\n  ['rightHip', 'rightKnee'], ['rightKnee', 'rightAnkle'],\n  ['leftShoulder', 'rightShoulder'], ['leftHip', 'rightHip']\n];\n\n/*\n * Define the skeleton. This defines the parent->child relationships of our\n * tree. Arbitrarily this defines the nose as the root of the tree, however\n * since we will infer the displacement for both parent->child and\n * child->parent, we can define the tree root as any node.\n */\nexport const poseChain: StringTuple[] = [\n  ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'],\n  ['rightEye', 'rightEar'], ['nose', 'leftShoulder'],\n  ['leftShoulder', 'leftElbow'], ['leftElbow', 'leftWrist'],\n  ['leftShoulder', 'leftHip'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['nose', 'rightShoulder'],\n  ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],\n  ['rightShoulder', 'rightHip'], ['rightHip', 'rightKnee'],\n  ['rightKnee', 'rightAnkle']\n];\n\nexport const connectedPartIndices = connectedPartNames.map(\n    ([jointNameA, jointNameB]) => ([partIds[jointNameA], partIds[jointNameB]]));\n\nexport const partChannels: string[] = [\n  'left_face',\n  'right_face',\n  'right_upper_leg_front',\n  'right_lower_leg_back',\n  'right_upper_leg_back',\n  'left_lower_leg_front',\n  'left_upper_leg_front',\n  'left_upper_leg_back',\n  'left_lower_leg_back',\n  'right_feet',\n  'right_lower_leg_front',\n  'left_feet',\n  'torso_front',\n  'torso_back',\n  'right_upper_arm_front',\n  'right_upper_arm_back',\n  'right_lower_arm_back',\n  'left_lower_arm_front',\n  'left_upper_arm_front',\n  'left_upper_arm_back',\n  'left_lower_arm_back',\n  'right_hand',\n  'right_lower_arm_front',\n  'left_hand'\n];\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Part, TensorBuffer3D, Vector2D} from '../types';\n\nexport function getOffsetPoint(\n    y: number, x: number, keypoint: number, offsets: TensorBuffer3D): Vector2D {\n  return {\n    y: offsets.get(y, x, keypoint),\n    x: offsets.get(y, x, keypoint + NUM_KEYPOINTS)\n  };\n}\n\nexport function getImageCoords(\n    part: Part, outputStride: number, offsets: TensorBuffer3D): Vector2D {\n  const {heatmapY, heatmapX, id: keypoint} = part;\n  const {y, x} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets);\n  return {\n    x: part.heatmapX * outputStride + x,\n    y: part.heatmapY * outputStride + y\n  };\n}\n\nexport function fillArray<T>(element: T, size: number): T[] {\n  const result: T[] = new Array(size);\n\n  for (let i = 0; i < size; i++) {\n    result[i] = element;\n  }\n\n  return result;\n}\n\nexport function clamp(a: number, min: number, max: number): number {\n  if (a < min) {\n    return min;\n  }\n  if (a > max) {\n    return max;\n  }\n  return a;\n}\n\nexport function squaredDistance(\n    y1: number, x1: number, y2: number, x2: number): number {\n  const dy = y2 - y1;\n  const dx = x2 - x1;\n  return dy * dy + dx * dx;\n}\n\nexport function addVectors(a: Vector2D, b: Vector2D): Vector2D {\n  return {x: a.x + b.x, y: a.y + b.y};\n}\n\nexport function clampVector(a: Vector2D, min: number, max: number): Vector2D {\n  return {y: clamp(a.y, min, max), x: clamp(a.x, min, max)};\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumberTuple, partIds, partNames, poseChain} from '../keypoints';\nimport {Keypoint, PartWithScore, TensorBuffer3D, Vector2D} from '../types';\n\nimport {clamp, getOffsetPoint} from './util';\nimport {addVectors, getImageCoords} from './util';\n\nconst parentChildrenTuples: NumberTuple[] = poseChain.map(\n    ([parentJoinName, childJoinName]): NumberTuple =>\n        ([partIds[parentJoinName], partIds[childJoinName]]));\n\nconst parentToChildEdges: number[] =\n    parentChildrenTuples.map(([, childJointId]) => childJointId);\n\nconst childToParentEdges: number[] =\n    parentChildrenTuples.map(([\n                               parentJointId,\n                             ]) => parentJointId);\n\nfunction getDisplacement(\n    edgeId: number, point: Vector2D, displacements: TensorBuffer3D): Vector2D {\n  const numEdges = displacements.shape[2] / 2;\n  return {\n    y: displacements.get(point.y, point.x, edgeId),\n    x: displacements.get(point.y, point.x, numEdges + edgeId)\n  };\n}\n\nfunction getStridedIndexNearPoint(\n    point: Vector2D, outputStride: number, height: number,\n    width: number): Vector2D {\n  return {\n    y: clamp(Math.round(point.y / outputStride), 0, height - 1),\n    x: clamp(Math.round(point.x / outputStride), 0, width - 1)\n  };\n}\n\n/**\n * We get a new keypoint along the `edgeId` for the pose instance, assuming\n * that the position of the `idSource` part is already known. For this, we\n * follow the displacement vector from the source to target part (stored in\n * the `i`-t channel of the displacement tensor). The displaced keypoint\n * vector is refined using the offset vector by `offsetRefineStep` times.\n */\nfunction traverseToTargetKeypoint(\n    edgeId: number, sourceKeypoint: Keypoint, targetKeypointId: number,\n    scoresBuffer: TensorBuffer3D, offsets: TensorBuffer3D, outputStride: number,\n    displacements: TensorBuffer3D, offsetRefineStep = 2): Keypoint {\n  const [height, width] = scoresBuffer.shape;\n\n  // Nearest neighbor interpolation for the source->target displacements.\n  const sourceKeypointIndices = getStridedIndexNearPoint(\n      sourceKeypoint.position, outputStride, height, width);\n\n  const displacement =\n      getDisplacement(edgeId, sourceKeypointIndices, displacements);\n\n  const displacedPoint = addVectors(sourceKeypoint.position, displacement);\n  let targetKeypoint = displacedPoint;\n  for (let i = 0; i < offsetRefineStep; i++) {\n    const targetKeypointIndices =\n        getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n\n    const offsetPoint = getOffsetPoint(\n        targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId,\n        offsets);\n\n    targetKeypoint = addVectors(\n        {\n          x: targetKeypointIndices.x * outputStride,\n          y: targetKeypointIndices.y * outputStride\n        },\n        {x: offsetPoint.x, y: offsetPoint.y});\n  }\n  const targetKeyPointIndices =\n      getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n  const score = scoresBuffer.get(\n      targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);\n\n  return {position: targetKeypoint, part: partNames[targetKeypointId], score};\n}\n\n/**\n * Follows the displacement fields to decode the full pose of the object\n * instance given the position of a part that acts as root.\n *\n * @return An array of decoded keypoints and their scores for a single pose\n */\nexport function decodePose(\n    root: PartWithScore, scores: TensorBuffer3D, offsets: TensorBuffer3D,\n    outputStride: number, displacementsFwd: TensorBuffer3D,\n    displacementsBwd: TensorBuffer3D): Keypoint[] {\n  const numParts = scores.shape[2];\n  const numEdges = parentToChildEdges.length;\n\n  const instanceKeypoints: Keypoint[] = new Array(numParts);\n  // Start a new detection instance at the position of the root.\n  const {part: rootPart, score: rootScore} = root;\n  const rootPoint = getImageCoords(rootPart, outputStride, offsets);\n\n  instanceKeypoints[rootPart.id] = {\n    score: rootScore,\n    part: partNames[rootPart.id],\n    position: rootPoint\n  };\n\n  // Decode the part positions upwards in the tree, following the backward\n  // displacements.\n  for (let edge = numEdges - 1; edge >= 0; --edge) {\n    const sourceKeypointId = parentToChildEdges[edge];\n    const targetKeypointId = childToParentEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsBwd);\n    }\n  }\n\n  // Decode the part positions downwards in the tree, following the forward\n  // displacements.\n  for (let edge = 0; edge < numEdges; ++edge) {\n    const sourceKeypointId = childToParentEdges[edge];\n    const targetKeypointId = parentToChildEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsFwd);\n    }\n  }\n\n  return instanceKeypoints;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Keypoint, Pose, TensorBuffer3D} from '../types';\n\nimport {buildPartWithScoreQueue} from './build_part_with_score_queue';\nimport {decodePose} from './decode_pose';\nimport {getImageCoords, squaredDistance} from './util';\n\nfunction withinNmsRadiusOfCorrespondingPoint(\n    poses: Pose[], squaredNmsRadius: number, {x, y}: {x: number, y: number},\n    keypointId: number): boolean {\n  return poses.some(({keypoints}) => {\n    const correspondingKeypoint = keypoints[keypointId].position;\n    return squaredDistance(\n               y, x, correspondingKeypoint.y, correspondingKeypoint.x) <=\n        squaredNmsRadius;\n  });\n}\n\n/* Score the newly proposed object instance without taking into account\n * the scores of the parts that overlap with any previously detected\n * instance.\n */\nfunction getInstanceScore(\n    existingPoses: Pose[], squaredNmsRadius: number,\n    instanceKeypoints: Keypoint[]): number {\n  let notOverlappedKeypointScores = instanceKeypoints.reduce(\n      (result, {position, score}, keypointId): number => {\n        if (!withinNmsRadiusOfCorrespondingPoint(\n                existingPoses, squaredNmsRadius, position, keypointId)) {\n          result += score;\n        }\n        return result;\n      }, 0.0);\n\n  return notOverlappedKeypointScores /= instanceKeypoints.length;\n}\n\n// A point (y, x) is considered as root part candidate if its score is a\n// maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=\n// kLocalMaximumRadius.\nconst kLocalMaximumRadius = 1;\n\n/**\n * Detects multiple poses and finds their parts from part scores and\n * displacement vectors. It returns up to `maxDetections` object instance\n * detections in decreasing root score order. It works as follows: We first\n * create a priority queue with local part score maxima above\n * `scoreThreshold`, considering all parts at the same time. Then we\n * iteratively pull the top  element of the queue (in decreasing score order)\n * and treat it as a root candidate for a new object instance. To avoid\n * duplicate detections, we reject the root candidate if it is within a disk\n * of `nmsRadius` pixels from the corresponding part of a previously detected\n * instance, which is a form of part-based non-maximum suppression (NMS). If\n * the root candidate passes the NMS check, we start a new object instance\n * detection, treating the corresponding part as root and finding the\n * positions of the remaining parts by following the displacement vectors\n * along the tree-structured part graph. We assign to the newly detected\n * instance a score equal to the sum of scores of its parts which have not\n * been claimed by a previous instance (i.e., those at least `nmsRadius`\n * pixels away from the corresponding part of all previously detected\n * instances), divided by the total number of parts `numParts`.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param displacementsFwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the forward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param displacementsBwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the backward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @param maxPoseDetections Maximum number of returned instance detections per\n * image.\n *\n * @param scoreThreshold Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5.\n *\n * @param nmsRadius Non-maximum suppression part distance. It needs to be\n * strictly positive. Two parts suppress each other if they are less than\n * `nmsRadius` pixels away. Defaults to 20.\n *\n * @return An array of poses and their scores, each containing keypoints and\n * the corresponding keypoint scores.\n */\nexport function decodeMultiplePoses(\n    scoresBuffer: TensorBuffer3D, offsetsBuffer: TensorBuffer3D,\n    displacementsFwdBuffer: TensorBuffer3D,\n    displacementsBwdBuffer: TensorBuffer3D, outputStride: number,\n    maxPoseDetections: number, scoreThreshold = 0.5, nmsRadius = 20): Pose[] {\n  const poses: Pose[] = [];\n\n  const queue = buildPartWithScoreQueue(\n      scoreThreshold, kLocalMaximumRadius, scoresBuffer);\n\n  const squaredNmsRadius = nmsRadius * nmsRadius;\n\n  // Generate at most maxDetections object instances per image in\n  // decreasing root part score order.\n  while (poses.length < maxPoseDetections && !queue.empty()) {\n    // The top element in the queue is the next root candidate.\n    const root = queue.dequeue();\n\n    // Part-based non-maximum suppression: We reject a root candidate if it\n    // is within a disk of `nmsRadius` pixels from the corresponding part of\n    // a previously detected instance.\n    const rootImageCoords =\n        getImageCoords(root.part, outputStride, offsetsBuffer);\n    if (withinNmsRadiusOfCorrespondingPoint(\n            poses, squaredNmsRadius, rootImageCoords, root.part.id)) {\n      continue;\n    }\n\n    // Start a new detection instance at the position of the root.\n    const keypoints = decodePose(\n        root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer,\n        displacementsBwdBuffer);\n\n    const score = getInstanceScore(poses, squaredNmsRadius, keypoints);\n\n    poses.push({keypoints, score});\n  }\n\n  return poses;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nfunction mod(a: tf.Tensor1D, b: number): tf.Tensor1D {\n  return tf.tidy(() => {\n    const floored = tf.div(a, tf.scalar(b, 'int32'));\n\n    return tf.sub(a, tf.mul(floored, tf.scalar(b, 'int32')));\n  });\n}\n\nexport function argmax2d(inputs: tf.Tensor3D): tf.Tensor2D {\n  const [height, width, depth] = inputs.shape;\n\n  return tf.tidy(() => {\n    const reshaped = tf.reshape(inputs, [height * width, depth]);\n    const coords = tf.argMax(reshaped, 0);\n\n    const yCoords = tf.expandDims(tf.div(coords, tf.scalar(width, 'int32')), 1);\n    const xCoords = tf.expandDims(mod(coords as tf.Tensor1D, width), 1);\n\n    return tf.concat([yCoords, xCoords], 1);\n  }) as tf.Tensor2D;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Vector2D} from '../types';\n\nexport function getPointsConfidence(\n    heatmapScores: tf.TensorBuffer<tf.Rank.R3>,\n    heatMapCoords: tf.TensorBuffer<tf.Rank.R2>): Float32Array {\n  const numKeypoints = heatMapCoords.shape[0];\n  const result = new Float32Array(numKeypoints);\n\n  for (let keypoint = 0; keypoint < numKeypoints; keypoint++) {\n    const y = heatMapCoords.get(keypoint, 0);\n    const x = heatMapCoords.get(keypoint, 1);\n    result[keypoint] = heatmapScores.get(y, x, keypoint);\n  }\n\n  return result;\n}\n\nfunction getOffsetPoint(\n    y: number, x: number, keypoint: number,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): Vector2D {\n  return {\n    y: offsetsBuffer.get(y, x, keypoint),\n    x: offsetsBuffer.get(y, x, keypoint + NUM_KEYPOINTS)\n  };\n}\n\nexport function getOffsetVectors(\n    heatMapCoordsBuffer: tf.TensorBuffer<tf.Rank.R2>,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): tf.Tensor2D {\n  const result: number[] = [];\n\n  for (let keypoint = 0; keypoint < NUM_KEYPOINTS; keypoint++) {\n    const heatmapY = heatMapCoordsBuffer.get(keypoint, 0).valueOf();\n    const heatmapX = heatMapCoordsBuffer.get(keypoint, 1).valueOf();\n\n    const {x, y} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsetsBuffer);\n\n    result.push(y);\n    result.push(x);\n  }\n\n  return tf.tensor2d(result, [NUM_KEYPOINTS, 2]);\n}\n\nexport function getOffsetPoints(\n    heatMapCoordsBuffer: tf.TensorBuffer<tf.Rank.R2>, outputStride: number,\n    offsetsBuffer: tf.TensorBuffer<tf.Rank.R3>): tf.Tensor2D {\n  return tf.tidy(() => {\n    const offsetVectors = getOffsetVectors(heatMapCoordsBuffer, offsetsBuffer);\n\n    return tf\n        .add(tf\n          .cast(tf\n            .mul(heatMapCoordsBuffer.toTensor(), tf.scalar(outputStride,\n              'int32')), 'float32'), offsetVectors);\n  });\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {partNames} from '../keypoints';\nimport {Keypoint, Pose, PoseNetOutputStride} from '../types';\n\nimport {argmax2d} from './argmax2d';\nimport {getOffsetPoints, getPointsConfidence} from './util';\n\n/**\n * Detects a single pose and finds its parts from part scores and offset\n * vectors. It returns a single pose detection. It works as follows:\n * argmax2d is done on the scores to get the y and x index in the heatmap\n * with the highest score for each part, which is essentially where the\n * part is most likely to exist. This produces a tensor of size 17x2, with\n * each row being the y and x index in the heatmap for each keypoint.\n * The offset vector for each for each part is retrieved by getting the\n * y and x from the offsets corresponding to the y and x index in the\n * heatmap for that part. This produces a tensor of size 17x2, with each\n * row being the offset vector for the corresponding keypoint.\n * To get the keypoint, each parts heatmap y and x are multiplied\n * by the output stride then added to their corresponding offset vector,\n * which is in the same scale as the original image.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @return A promise that resolves with single pose with a confidence score,\n * which contains an array of keypoints indexed by part id, each with a score\n * and position.\n */\nexport async function decodeSinglePose(\n    heatmapScores: tf.Tensor3D, offsets: tf.Tensor3D,\n    outputStride: PoseNetOutputStride): Promise<Pose> {\n  let totalScore = 0.0;\n\n  const heatmapValues = argmax2d(heatmapScores);\n\n  const allTensorBuffers = await Promise.all(\n      [heatmapScores.buffer(), offsets.buffer(), heatmapValues.buffer()]);\n\n  const scoresBuffer = allTensorBuffers[0];\n  const offsetsBuffer = allTensorBuffers[1];\n  const heatmapValuesBuffer = allTensorBuffers[2];\n\n  const offsetPoints =\n      getOffsetPoints(heatmapValuesBuffer, outputStride, offsetsBuffer);\n  const offsetPointsBuffer = await offsetPoints.buffer();\n\n  const keypointConfidence =\n      Array.from(getPointsConfidence(scoresBuffer, heatmapValuesBuffer));\n\n  const keypoints = keypointConfidence.map((score, keypointId): Keypoint => {\n    totalScore += score;\n    return {\n      position: {\n        y: offsetPointsBuffer.get(keypointId, 0),\n        x: offsetPointsBuffer.get(keypointId, 1)\n      },\n      part: partNames[keypointId],\n      score\n    };\n  });\n\n  heatmapValues.dispose();\n  offsetPoints.dispose();\n\n  return {keypoints, score: totalScore / keypoints.length};\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nconst MOBILENET_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/mobilenet/';\nconst RESNET50_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/posenet/resnet50/';\n\n// The PoseNet 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function resNet50Checkpoint(stride: number, quantBytes: number): string {\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n  if (quantBytes === 4) {\n    return RESNET50_BASE_URL + `float/` + graphJson;\n  } else {\n    return RESNET50_BASE_URL + `quant${quantBytes}/` + graphJson;\n  }\n}\n\n// The PoseNet 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function mobileNetCheckpoint(\n    stride: number, multiplier: number, quantBytes: number): string {\n  const toStr: {[key: number]: string} = {1.0: '100', 0.75: '075', 0.50: '050'};\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision checkpoints.\n  if (quantBytes === 4) {\n    return MOBILENET_BASE_URL + `float/${toStr[multiplier]}/` + graphJson;\n  } else {\n    return MOBILENET_BASE_URL + `quant${quantBytes}/${toStr[multiplier]}/` +\n        graphJson;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\n\nconst imageNetMean = [-123.15, -115.90, -103.06];\n\nexport class ResNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    return tf.add(input, imageNetMean);\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [displacementFwd, displacementBwd, offsets, heatmap] = results;\n    return {offsets, heatmap, displacementFwd, displacementBwd};\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {connectedPartIndices} from './keypoints';\nimport {InputResolution, Keypoint, Padding, Pose, PosenetInput, PoseNetOutputStride, TensorBuffer3D, Vector2D} from './types';\n\nfunction eitherPointDoesntMeetConfidence(\n    a: number, b: number, minConfidence: number): boolean {\n  return (a < minConfidence || b < minConfidence);\n}\n\nexport function getAdjacentKeyPoints(\n    keypoints: Keypoint[], minConfidence: number): Keypoint[][] {\n  return connectedPartIndices.reduce(\n      (result: Keypoint[][], [leftJoint, rightJoint]): Keypoint[][] => {\n        if (eitherPointDoesntMeetConfidence(\n                keypoints[leftJoint].score, keypoints[rightJoint].score,\n                minConfidence)) {\n          return result;\n        }\n\n        result.push([keypoints[leftJoint], keypoints[rightJoint]]);\n\n        return result;\n      }, []);\n}\n\nconst {NEGATIVE_INFINITY, POSITIVE_INFINITY} = Number;\nexport function getBoundingBox(keypoints: Keypoint[]):\n    {maxX: number, maxY: number, minX: number, minY: number} {\n  return keypoints.reduce(({maxX, maxY, minX, minY}, {position: {x, y}}) => {\n    return {\n      maxX: Math.max(maxX, x),\n      maxY: Math.max(maxY, y),\n      minX: Math.min(minX, x),\n      minY: Math.min(minY, y)\n    };\n  }, {\n    maxX: NEGATIVE_INFINITY,\n    maxY: NEGATIVE_INFINITY,\n    minX: POSITIVE_INFINITY,\n    minY: POSITIVE_INFINITY\n  });\n}\n\nexport function getBoundingBoxPoints(keypoints: Keypoint[]): Vector2D[] {\n  const {minX, minY, maxX, maxY} = getBoundingBox(keypoints);\n  return [\n    {x: minX, y: minY}, {x: maxX, y: minY}, {x: maxX, y: maxY},\n    {x: minX, y: maxY}\n  ];\n}\n\nexport async function toTensorBuffers3D(tensors: tf.Tensor3D[]):\n    Promise<TensorBuffer3D[]> {\n  return Promise.all(tensors.map(tensor => tensor.buffer()));\n}\n\nexport function scalePose(\n    pose: Pose, scaleY: number, scaleX: number, offsetY = 0,\n    offsetX = 0): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(({score, part, position}) => ({\n                                    score,\n                                    part,\n                                    position: {\n                                      x: position.x * scaleX + offsetX,\n                                      y: position.y * scaleY + offsetY\n                                    }\n                                  }))\n  };\n}\n\nexport function scalePoses(\n    poses: Pose[], scaleY: number, scaleX: number, offsetY = 0, offsetX = 0) {\n  if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {\n    return poses;\n  }\n  return poses.map(pose => scalePose(pose, scaleY, scaleX, offsetY, offsetX));\n}\n\nexport function flipPoseHorizontal(pose: Pose, imageWidth: number): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(\n        ({score, part, position}) => ({\n          score,\n          part,\n          position: {x: imageWidth - 1 - position.x, y: position.y}\n        }))\n  };\n}\n\nexport function flipPosesHorizontal(poses: Pose[], imageWidth: number) {\n  if (imageWidth <= 0) {\n    return poses;\n  }\n  return poses.map(pose => flipPoseHorizontal(pose, imageWidth));\n}\n\nexport function toValidInputResolution(\n    inputResolution: number, outputStride: PoseNetOutputStride): number {\n  if (isValidInputResolution(inputResolution, outputStride)) {\n    return inputResolution;\n  }\n\n  return Math.floor(inputResolution / outputStride) * outputStride + 1;\n}\n\nexport function validateInputResolution(inputResolution: InputResolution) {\n  tf.util.assert(\n      typeof inputResolution === 'number' ||\n          typeof inputResolution === 'object',\n      () => `Invalid inputResolution ${inputResolution}. ` +\n          `Should be a number or an object with width and height`);\n\n  if (typeof inputResolution === 'object') {\n    tf.util.assert(\n        typeof inputResolution.width === 'number',\n        () => `inputResolution.width has a value of ${\n            inputResolution.width} which is invalid; it must be a number`);\n    tf.util.assert(\n        typeof inputResolution.height === 'number',\n        () => `inputResolution.height has a value of ${\n            inputResolution.height} which is invalid; it must be a number`);\n  }\n}\n\nexport function getValidInputResolutionDimensions(\n    inputResolution: InputResolution,\n    outputStride: PoseNetOutputStride): [number, number] {\n  validateInputResolution(inputResolution);\n  if (typeof inputResolution === 'object') {\n    return [\n      toValidInputResolution(inputResolution.height, outputStride),\n      toValidInputResolution(inputResolution.width, outputStride),\n    ];\n  } else {\n    return [\n      toValidInputResolution(inputResolution, outputStride),\n      toValidInputResolution(inputResolution, outputStride),\n    ];\n  }\n}\n\nconst VALID_OUTPUT_STRIDES: PoseNetOutputStride[] = [8, 16, 32];\nexport function assertValidOutputStride(outputStride: PoseNetOutputStride) {\n  tf.util.assert(\n      typeof outputStride === 'number', () => 'outputStride is not a number');\n  tf.util.assert(\n      VALID_OUTPUT_STRIDES.indexOf(outputStride) >= 0,\n      () => `outputStride of ${outputStride} is invalid. ` +\n          `It must be either 8, 16, or 32`);\n}\n\nfunction isValidInputResolution(\n    resolution: number, outputStride: number): boolean {\n  return (resolution - 1) % outputStride === 0;\n}\n\nexport function assertValidResolution(\n    resolution: [number, number], outputStride: number) {\n  tf.util.assert(\n      typeof resolution[0] === 'number' && typeof resolution[1] === 'number',\n      () => `both resolution values must be a number but had values ${\n          resolution}`);\n\n  tf.util.assert(\n      isValidInputResolution(resolution[0], outputStride),\n      () => `height of ${resolution[0]} is invalid for output stride ` +\n          `${outputStride}.`);\n\n  tf.util.assert(\n      isValidInputResolution(resolution[1], outputStride),\n      () => `width of ${resolution[1]} is invalid for output stride ` +\n          `${outputStride}.`);\n}\n\nexport function getInputTensorDimensions(input: PosenetInput):\n    [number, number] {\n  return input instanceof tf.Tensor ? [input.shape[0], input.shape[1]] :\n                                      [input.height, input.width];\n}\n\nexport function toInputTensor(input: PosenetInput) {\n  return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\n}\n\nexport function toResizedInputTensor(\n    input: PosenetInput, resizeHeight: number, resizeWidth: number,\n    flipHorizontal: boolean): tf.Tensor3D {\n  return tf.tidy(() => {\n    const imageTensor = toInputTensor(input);\n\n    if (flipHorizontal) {\n      return tf.image.resizeBilinear(tf.reverse(imageTensor, 1), [resizeHeight, resizeWidth]);\n    } else {\n      return tf.image.resizeBilinear(imageTensor, [resizeHeight, resizeWidth]);\n    }\n  });\n}\n\nexport function padAndResizeTo(\n    input: PosenetInput, [targetH, targetW]: [number, number]):\n    {resized: tf.Tensor3D, padding: Padding} {\n  const [height, width] = getInputTensorDimensions(input);\n  const targetAspect = targetW / targetH;\n  const aspect = width / height;\n  let [padT, padB, padL, padR] = [0, 0, 0, 0];\n  if (aspect < targetAspect) {\n    // pads the width\n    padT = 0;\n    padB = 0;\n    padL = Math.round(0.5 * (targetAspect * height - width));\n    padR = Math.round(0.5 * (targetAspect * height - width));\n  } else {\n    // pads the height\n    padT = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padB = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padL = 0;\n    padR = 0;\n  }\n\n  const resized: tf.Tensor3D = tf.tidy(() => {\n    let imageTensor = toInputTensor(input);\n    imageTensor = tf.pad3d(imageTensor, [[padT, padB], [padL, padR], [0, 0]]);\n\n    return tf.image.resizeBilinear(imageTensor, [targetH, targetW]);\n  });\n\n  return {resized, padding: {top: padT, left: padL, right: padR, bottom: padB}};\n}\n\nexport function scaleAndFlipPoses(\n    poses: Pose[], [height, width]: [number, number],\n    [inputResolutionHeight, inputResolutionWidth]: [number, number],\n    padding: Padding, flipHorizontal: boolean): Pose[] {\n  const scaleY =\n      (height + padding.top + padding.bottom) / (inputResolutionHeight);\n  const scaleX =\n      (width + padding.left + padding.right) / (inputResolutionWidth);\n\n  const scaledPoses =\n      scalePoses(poses, scaleY, scaleX, -padding.top, -padding.left);\n\n  if (flipHorizontal) {\n    return flipPosesHorizontal(scaledPoses, width);\n  } else {\n    return scaledPoses;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\nimport {mobileNetCheckpoint, resNet50Checkpoint} from './checkpoints';\nimport {MobileNet} from './mobilenet';\nimport {decodeMultiplePoses} from './multi_pose/decode_multiple_poses';\nimport {ResNet} from './resnet';\nimport {decodeSinglePose} from './single_pose/decode_single_pose';\nimport {InputResolution, MobileNetMultiplier, Pose, PoseNetArchitecture, PosenetInput, PoseNetOutputStride, PoseNetQuantBytes} from './types';\nimport {assertValidOutputStride, assertValidResolution, getInputTensorDimensions, getValidInputResolutionDimensions, padAndResizeTo, scaleAndFlipPoses, toTensorBuffers3D, validateInputResolution} from './util';\n\n/**\n * PoseNet model loading is configurable using the following config dictionary.\n *\n * `architecture`: PoseNetArchitecture. It determines wich PoseNet architecture\n * to load. The supported architectures are: MobileNetV1 and ResNet.\n *\n * `outputStride`: Specifies the output stride of the PoseNet model.\n * The smaller the value, the larger the output resolution, and more accurate\n * the model at the cost of speed.  Set this to a larger value to increase speed\n * at the cost of accuracy. Stride 32 is supported for ResNet and\n * stride 8,16,32 are supported for various MobileNetV1 models.\n *\n * * `inputResolution`: A number or an Object of type {width: number, height:\n * number}. Specifies the size the input image is scaled to before feeding it\n * through the PoseNet model.  The larger the value, more accurate the model at\n * the cost of speed. Set this to a smaller value to increase speed at the cost\n * of accuracy. If a number is provided, the input will be resized and padded to\n * be a square with the same width and height.  If width and height are\n * provided, the input will be resized and padded to the specified width and\n * height.\n *\n * `multiplier`: An optional number with values: 1.01, 1.0, 0.75, or\n * 0.50. The value is used only by MobileNet architecture. It is the float\n * multiplier for the depth (number of channels) for all convolution ops.\n * The larger the value, the larger the size of the layers, and more accurate\n * the model at the cost of speed. Set this to a smaller value to increase speed\n * at the cost of accuracy.\n *\n * `modelUrl`: An optional string that specifies custom url of the model. This\n * is useful for area/countries that don't have access to the model hosted on\n * GCP.\n *\n * `quantBytes`: An opional number with values: 1, 2, or 4.  This parameter\n * affects weight quantization in the models. The available options are\n * 1 byte, 2 bytes, and 4 bytes. The higher the value, the larger the model size\n * and thus the longer the loading time, the lower the value, the shorter the\n * loading time but lower the accuracy.\n */\nexport interface ModelConfig {\n  architecture: PoseNetArchitecture;\n  outputStride: PoseNetOutputStride;\n  inputResolution: InputResolution;\n  multiplier?: MobileNetMultiplier;\n  modelUrl?: string;\n  quantBytes?: PoseNetQuantBytes;\n}\n\n// The default configuration for loading MobileNetV1 based PoseNet.\n//\n// (And for references, the default configuration for loading ResNet\n// based PoseNet is also included).\n//\n// ```\n// const RESNET_CONFIG = {\n//   architecture: 'ResNet50',\n//   outputStride: 32,\n//   quantBytes: 2,\n// } as ModelConfig;\n// ```\nconst MOBILENET_V1_CONFIG: ModelConfig = {\n  architecture: 'MobileNetV1',\n  outputStride: 16,\n  multiplier: 0.75,\n  inputResolution: 257,\n} as ModelConfig;\n\nconst VALID_ARCHITECTURE = ['MobileNetV1', 'ResNet50'];\nconst VALID_STRIDE = {\n  'MobileNetV1': [8, 16, 32],\n  'ResNet50': [32, 16]\n};\n\nconst VALID_MULTIPLIER = {\n  'MobileNetV1': [0.50, 0.75, 1.0],\n  'ResNet50': [1.0]\n};\nconst VALID_QUANT_BYTES = [1, 2, 4];\n\nfunction validateModelConfig(config: ModelConfig) {\n  config = config || MOBILENET_V1_CONFIG;\n\n  if (config.architecture == null) {\n    config.architecture = 'MobileNetV1';\n  }\n  if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {\n    throw new Error(\n        `Invalid architecture ${config.architecture}. ` +\n        `Should be one of ${VALID_ARCHITECTURE}`);\n  }\n\n  if (config.inputResolution == null) {\n    config.inputResolution = 257;\n  }\n\n  validateInputResolution(config.inputResolution);\n\n  if (config.outputStride == null) {\n    config.outputStride = 16;\n  }\n  if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {\n    throw new Error(\n        `Invalid outputStride ${config.outputStride}. ` +\n        `Should be one of ${VALID_STRIDE[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.multiplier == null) {\n    config.multiplier = 1.0;\n  }\n  if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {\n    throw new Error(\n        `Invalid multiplier ${config.multiplier}. ` +\n        `Should be one of ${VALID_MULTIPLIER[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.quantBytes == null) {\n    config.quantBytes = 4;\n  }\n  if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {\n    throw new Error(\n        `Invalid quantBytes ${config.quantBytes}. ` +\n        `Should be one of ${VALID_QUANT_BYTES} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.architecture === 'MobileNetV1' && config.outputStride === 32 &&\n      config.multiplier !== 1) {\n    throw new Error(\n        `When using an output stride of 32, ` +\n        `you must select 1 as the multiplier.`);\n  }\n\n  return config;\n}\n\n/**\n * PoseNet inference is configurable using the following config dictionary.\n *\n * `flipHorizontal`: If the poses should be flipped/mirrored horizontally.\n * This should be set to true for videos where the video is by default flipped\n * horizontally (i.e. a webcam), and you want the poses to be returned in the\n * proper orientation.\n *\n */\nexport interface InferenceConfig {\n  flipHorizontal: boolean;\n}\n\n/**\n * Single Person Inference Config\n */\nexport interface SinglePersonInterfaceConfig extends InferenceConfig {}\n\n/**\n * Multiple Person Inference Config\n *\n * `maxDetections`: Maximum number of returned instance detections per image.\n *\n * `scoreThreshold`: Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5\n *\n * `nmsRadius`: Non-maximum suppression part distance in pixels. It needs\n * to be strictly positive. Two parts suppress each other if they are less\n * than `nmsRadius` pixels away. Defaults to 20.\n */\nexport interface MultiPersonInferenceConfig extends InferenceConfig {\n  maxDetections?: number;\n  scoreThreshold?: number;\n  nmsRadius?: number;\n}\n\n// these added back to not break the existing api.\nexport interface LegacyMultiPersonInferenceConfig extends\n    MultiPersonInferenceConfig {\n  decodingMethod: 'multi-person';\n}\n\nexport interface LegacySinglePersonInferenceConfig extends\n    SinglePersonInterfaceConfig {\n  decodingMethod: 'single-person';\n}\n\nexport const SINGLE_PERSON_INFERENCE_CONFIG: SinglePersonInterfaceConfig = {\n  flipHorizontal: false\n};\n\nexport const MULTI_PERSON_INFERENCE_CONFIG: MultiPersonInferenceConfig = {\n  flipHorizontal: false,\n  maxDetections: 5,\n  scoreThreshold: 0.5,\n  nmsRadius: 20\n};\n\nfunction validateSinglePersonInferenceConfig(\n    config: SinglePersonInterfaceConfig) {}\n\nfunction validateMultiPersonInputConfig(config: MultiPersonInferenceConfig) {\n  const {maxDetections, scoreThreshold, nmsRadius} = config;\n\n  if (maxDetections <= 0) {\n    throw new Error(\n        `Invalid maxDetections ${maxDetections}. ` +\n        `Should be > 0`);\n  }\n\n  if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n    throw new Error(\n        `Invalid scoreThreshold ${scoreThreshold}. ` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (nmsRadius <= 0) {\n    throw new Error(`Invalid nmsRadius ${nmsRadius}.`);\n  }\n}\n\nexport class PoseNet {\n  readonly baseModel: BaseModel;\n  readonly inputResolution: [number, number];\n\n  constructor(net: BaseModel, inputResolution: [number, number]) {\n    assertValidOutputStride(net.outputStride);\n    assertValidResolution(inputResolution, net.outputStride);\n\n    this.baseModel = net;\n    this.inputResolution = inputResolution;\n  }\n\n  /**\n   * Infer through PoseNet, and estimates multiple poses using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns up to\n   * `config.maxDetections` object instance detections in decreasing root\n   * score order.\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config MultiPoseEstimationConfig object that contains parameters\n   * for the PoseNet inference using multiple pose estimation.\n   *\n   * @return An array of poses and their scores, each containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateMultiplePoses(\n      input: PosenetInput,\n      config: MultiPersonInferenceConfig = MULTI_PERSON_INFERENCE_CONFIG):\n      Promise<Pose[]> {\n    const configWithDefaults: MultiPersonInferenceConfig = {\n      ...MULTI_PERSON_INFERENCE_CONFIG,\n      ...config\n    };\n\n    validateMultiPersonInputConfig(config);\n\n    const outputStride = this.baseModel.outputStride;\n    const inputResolution = this.inputResolution;\n\n    const [height, width] = getInputTensorDimensions(input);\n\n    const {resized, padding} = padAndResizeTo(input, inputResolution);\n\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        this.baseModel.predict(resized);\n\n    const allTensorBuffers = await toTensorBuffers3D(\n        [heatmapScores, offsets, displacementFwd, displacementBwd]);\n\n    const scoresBuffer = allTensorBuffers[0];\n    const offsetsBuffer = allTensorBuffers[1];\n    const displacementsFwdBuffer = allTensorBuffers[2];\n    const displacementsBwdBuffer = allTensorBuffers[3];\n\n    const poses = await decodeMultiplePoses(\n        scoresBuffer, offsetsBuffer, displacementsFwdBuffer,\n        displacementsBwdBuffer, outputStride, configWithDefaults.maxDetections,\n        configWithDefaults.scoreThreshold, configWithDefaults.nmsRadius);\n\n    const resultPoses = scaleAndFlipPoses(\n        poses, [height, width], inputResolution, padding,\n        configWithDefaults.flipHorizontal);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n    resized.dispose();\n\n    return resultPoses;\n  }\n\n  /**\n   * Infer through PoseNet, and estimates a single pose using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns a single pose\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config SinglePersonEstimationConfig object that contains\n   * parameters for the PoseNet inference using single pose estimation.\n   *\n   * @return An pose and its scores, containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateSinglePose(\n      input: PosenetInput,\n      config: SinglePersonInterfaceConfig = SINGLE_PERSON_INFERENCE_CONFIG):\n      Promise<Pose> {\n    const configWithDefaults = {...SINGLE_PERSON_INFERENCE_CONFIG, ...config};\n\n    validateSinglePersonInferenceConfig(configWithDefaults);\n\n    const outputStride = this.baseModel.outputStride;\n    const inputResolution = this.inputResolution;\n\n    const [height, width] = getInputTensorDimensions(input);\n\n    const {resized, padding} = padAndResizeTo(input, inputResolution);\n\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        this.baseModel.predict(resized);\n\n    const pose = await decodeSinglePose(heatmapScores, offsets, outputStride);\n    const poses = [pose];\n\n    const resultPoses = scaleAndFlipPoses(\n        poses, [height, width], inputResolution, padding,\n        configWithDefaults.flipHorizontal);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n    resized.dispose();\n\n    return resultPoses[0];\n  }\n\n  /** Deprecated: Use either estimateSinglePose or estimateMultiplePoses */\n  async estimatePoses(\n      input: PosenetInput,\n      config: LegacySinglePersonInferenceConfig|\n      LegacyMultiPersonInferenceConfig): Promise<Pose[]> {\n    if (config.decodingMethod === 'single-person') {\n      const pose = await this.estimateSinglePose(input, config);\n      return [pose];\n    } else {\n      return this.estimateMultiplePoses(input, config);\n    }\n  }\n\n  public dispose() {\n    this.baseModel.dispose();\n  }\n}\n\nasync function loadMobileNet(config: ModelConfig): Promise<PoseNet> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  const multiplier = config.multiplier;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = mobileNetCheckpoint(outputStride, multiplier, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const mobilenet = new MobileNet(graphModel, outputStride);\n\n  const validInputResolution = getValidInputResolutionDimensions(\n      config.inputResolution, mobilenet.outputStride);\n\n  return new PoseNet(mobilenet, validInputResolution);\n}\n\nasync function loadResNet(config: ModelConfig): Promise<PoseNet> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = resNet50Checkpoint(outputStride, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const resnet = new ResNet(graphModel, outputStride);\n  const validInputResolution = getValidInputResolutionDimensions(\n      config.inputResolution, resnet.outputStride);\n  return new PoseNet(resnet, validInputResolution);\n}\n\n/**\n * Loads the PoseNet model instance from a checkpoint, with the ResNet\n * or MobileNet architecture. The model to be loaded is configurable using the\n * config dictionary ModelConfig. Please find more details in the\n * documentation of the ModelConfig.\n *\n * @param config ModelConfig dictionary that contains parameters for\n * the PoseNet loading process. Please find more details of each parameters\n * in the documentation of the ModelConfig interface. The predefined\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\n * for defining your customized config.\n */\nexport async function load(config: ModelConfig = MOBILENET_V1_CONFIG):\n    Promise<PoseNet> {\n  config = validateModelConfig(config);\n  if (config.architecture === 'ResNet50') {\n    return loadResNet(config);\n  } else if (config.architecture === 'MobileNetV1') {\n    return loadMobileNet(config);\n  } else {\n    return null;\n  }\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.2.2';\nexport {version};\n"]},"metadata":{},"sourceType":"module"}